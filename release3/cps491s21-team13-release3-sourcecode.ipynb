{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZm7vYUv2Arv"
   },
   "source": [
    "Zachary Rowland\n",
    "\n",
    "# CPS 491 Main Jupyter Notebook\n",
    "\n",
    "Contents\n",
    "\n",
    "- [Python Imports](#Python-Imports) Python imports for the whole document\n",
    "- [Introduction](#Introduction) Project motivation\n",
    "- [Discovering Functions using SINDy](#Discovering-Functions-Using-SINDy) Introduction to SINDy and model fitting using regression\n",
    "- [Applying SINDy to MNIST](#Applying-SINDy-to-MNIST) Experimenting with finding concise equations for image classification.\n",
    "- [Maclaurin Series Approximations](#Maclaurin-Series-Approximations) Older work experimenting with Maclaurin approximations.\n",
    "- [Change-of-Basis Approximation Strategy](#Change-of-Basis-Approximation-Strategy) A general approximation technique using one hidden layer and an arbitrary activation function.\n",
    "- [Approximating an Arbitrary Function using Convolution](#Approximating-an-Arbitrary-Function-using-Convolution) A method for approximating an arbitrary function inspired by convolution.\n",
    "- [Helpful Mathematical Theory](#Helpful-Mathematical-Theory) Math that might be related to the direction of the project.\n",
    "- [Related Work](#Related-Work) A small literature review of model compression and approximation theory of neural networks.\n",
    "\n",
    "[Tensorflow Guide](https://www.tensorflow.org/guide/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIBLLa2_2lQN"
   },
   "source": [
    "# Python Imports\n",
    "\n",
    "These are just global imports that are used by the whole document. Run the following cell before running anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Qq7w88-22nnh"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz as gv\n",
    "import sklearn.linear_model\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from IPython.display import display, Math, Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GaeUpA0Zc9u3"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Learning systems have always been an important part of data analysis. The simplest method of learning a function from data is the linear regression, but today's deep neural networks have proven capable of learning a variety of non-linear functions. However, deep neural networks are still shrowded in an air of mystery because of their complexity. Deep neural networks commonly have thousands of parameters that describe the precise function that the network implements as opposed to the two parameters learned by a simple linear regression. The main benefit of increasing the number of parameters is increasing expressivity, the amount and types of functions that can be learned. But the downside of expressive learning systems is intractable resulting models.\n",
    "\n",
    "Many researchers interested in applying deep learning consider trading tractability for expressivity to be an acceptable trade-off. However, [Lin et. al.](https://arxiv.org/pdf/1608.08225.pdf) questions if this exchange is necessary. Most phenomena in the natural sciences can be described with low-complexity mathematical models built from a combination of a small number of simple \"base functions\" such as polynomials, sinusoids, and exponentials. This insight suggests that neural networks are probably much more complex than is necessary to express the functions they are learning. Large sections of a trained network might be performing meaningless computations, or performing useful computations that could be computed with less machinary.\n",
    "\n",
    "The inscrutible nature of DNNs motivates research into smaller learning systems that that are more tractable.\n",
    "\n",
    "1. **Model compression** attempts to reduce the complexity of a trained DNN by pruning pieces off of the network that are deemed unnecessary.\n",
    "2. **Alternative learning systems** such as fuzzy inference systems attempt to make the function-approximation framework itself intuitive to humans.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POCjrhlSnvOo"
   },
   "source": [
    "# Searching for an Analytical Model Compression Scheme\n",
    "\n",
    "Part of the reason neural networks are hard to understand is that their mathematical representation is dissimilar to any other mathematical models we usually come across. To illustrate, consider the following function that represents some trained neural network with three hidden nodes using the standard sigmoid activation function $\\sigma(x) = (1+e^{-x})^{-1}$.\n",
    "\n",
    "$$ f(x) = 1.98\\sigma(2.32x - 0.27) + 2.18\\sigma(-2.20x + 6.91) + 1.81\\sigma(2.37x -14.45) - 3.07 $$\n",
    "\n",
    "This function turns out to be a very good approximation of $\\sin(x)$ for $x \\in [0, 2\\pi]$. However, the only way we know that is from a crude analysis of the outputs such as a root-mean-square comparison.\n",
    "A good question is whether or not there is some theory that formalizes, and makes intuitive, the connection between the parameters and structure of $f$ and the more commonly used sine function.\n",
    "\n",
    "To illustrate the challenge, consider the set of polynomial functions $\\mathbb{R} \\rightarrow \\mathbb{R}$ of the form $p(x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2 \\cdots + \\theta_d x^d$. Given data $(x_0, y_0)...(x_n, y_n)$, a unique $n$-degree polynomial that precisely models this data can be found by solving a simple linear system (assuming the $x_i$ values are all different).\n",
    "\n",
    "$$ \\pmb{0} = X\\pmb{\\theta} - \\pmb{y} $$\n",
    "$$ \\begin{bmatrix} 0 \\\\ 0 \\\\ \\vdots \\end{bmatrix} = \\begin{bmatrix} 1 & x_0 & x_0^2 & \\\\ 1 & x_1 & x_1^2 & \\cdots \\\\ & \\vdots \\end{bmatrix} \\begin{bmatrix} \\theta_0 \\\\ \\theta_1 \\\\ \\vdots \\end{bmatrix} - \\begin{bmatrix} y_0 \\\\ y_1 \\\\ \\vdots \\end{bmatrix}  $$\n",
    "\n",
    "Lower-degree, best-fit polynomials can be found through a similar method called regression. For degrees less than $n$, the $X$ matrix becomes non-square and the system above will probably be unsolvable. So instead, the goal is to minimize the distance between $X\\pmb{\\theta} - \\pmb{y}$ and the zero vector:\n",
    "$$ \\pmb{\\theta} = \\min_{\\theta} || X\\theta - \\pmb{y} ||^2 $$\n",
    "This problem can be viewed as finding the point on an embedded hyperplane that is closest to the origin. This means that the parameters $\\pmb{\\theta}$ are unique, and an method for finding these parameters such as gradient descent should always converge to this unique answer. Furthermore, there is established theory on finding polynomial approximations for other common functions such as Taylor expansions.\n",
    "\n",
    "Neural networks, on the otherhand, do not have these nice properties. Given a neural network $f(x;\\theta)$ trained to learn some true function $g(x)$:\n",
    "\n",
    "1. The parameters $\\theta$ are not necessarily unique. Different sets of parameters could give two different globally optimal functions (or the same optimal function expressed with different parameter sets).\n",
    "2. The parameters $\\theta$ learned from an iterative process such as gradient descent are not guarenteed to be not globally optimal, only _locally optimal_ as determined by the values to which $\\theta$ was initialized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "en1Gx53UcGZl"
   },
   "source": [
    "One way we could start is by defining a mechanized scheme for how a neural network _could_ approximate a given function, but not necessarily how the network _will_ approximate that function after training. For example, Lin points out that the operation of multipliying two real numbers $\\mathbb{R}^2 \\rightarrow \\mathbb{R}$ can be approximated to arbitrary accuracy with a 3-layer network with 4 hidden nodes:\n",
    "\n",
    "$$ \\text{mult}(x_1, x_2) = \\lim_{h \\rightarrow 0} \\frac{\\sigma(ha) + \\sigma(-ha) - \\sigma(hb) - \\sigma(-hb)}{4 h^2 \\sigma''(0)} $$\n",
    "\n",
    "$$ \\text{where}\\ \\ a = x_1 + x_2 \\qquad b = x_1 - x_2 $$\n",
    "\n",
    "This approximation is independent of the activation function $\\sigma$ used, only requiring $\\sigma''(0) \\ne 0$. This multiplication operation can be used to construct neural networks that approximate any polynomial. The only additional component needed is a way to propogate values unchanged from one layer to the next, in other words, an approximation of the identity function:\n",
    "\n",
    "$$ \\text{id}(x) = x = \\lim_{h \\rightarrow 0} \\frac{\\sigma(hx) - a(0)}{h \\sigma'(0)} $$\n",
    "\n",
    "These two components, along with the native addition operation, can be used to define neural networks that approximate any multivariate polynomial. Furthermore, Taylor's theorem provides a way of constructing polynomials that approximate any differentiable curve on some domain. Consequently, given a function $g$, we can generate sequences of neural networks that approach $g$ by changing $h$ or by approximating more terms in the Taylor expansion of $g$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Avdj7EjWfLXd"
   },
   "source": [
    "Theoretically, a tool could be built that searches for these Taylor constructions in trained neural networks and identifies the original function being approximated. However, building such a tool might not be practical or desirable for a number of reasons.\n",
    "\n",
    "First, there are many ways of combining $\\text{mult}$ and $\\text{id}$ to approximate a particular polynomial. For example, different compositions of multiplication often yield the same power of $x$ e.g. $\\text{mult}(\\text{mult}(x, x), \\text{mult}(x, x)) = \\text{mult}(x, \\text{mult}(x, \\text{mult}(x, x)))$. This means that the set of network configurations we are searching for is large and hard to describe.\n",
    "\n",
    "Second, requiring $h$ to approach zero leads to neural networks with very large and small parameters, especially as powers of $h$ become involved. In practice, neural networks are initialized randomly with numbers roughly in the single digits, and the training rate will probably be too small to push these parameters high enough while simultaneously being too large to make subtle changes to parameters close to zero. In essence, real networks will almost certainly never learn parameters like this.\n",
    "\n",
    "To summarize, any theory behind neural networks would have to keep in mind how neural networks are actually constructed and how they learn: they are constructed using sigmoid-like activation functions and learn using an iterative refinement process that finds a local best approximation based on a root-mean-square error calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9NWJxfq-9dK"
   },
   "source": [
    "# Data-Driven Approach\n",
    "\n",
    "The difficulties of understanding DNNs analytically motivate a more data-driven approach of model compression. A data-driven approach ignores the structure of a neural network entirely and only uses the network to generate data. The data generated by the machine is then fitted with a mathematical model. For regression problems, a data-driven system that learns mathematical equations has potential to replace the neural network altogether. Alternatively, if the trained neural network is not fully connected, the network could be collapsed into equations section-by-section, and the learned equations could then be composed to represent the whole network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPh35ur6hgj1"
   },
   "source": [
    "# Discovering Functions Using SINDy\n",
    "\n",
    "Paper: \\\\\n",
    "Brunton, Steven L., et. al. \"Sparse Identification of Nonlinear Dynamics with Control (SINDYc).\" 2016. https://arxiv.org/abs/1605.06682.\n",
    "\n",
    "SINDy is a method for fitting functions to time data using linear regression. SINDy finds a best fit function of the form $f(x) = w_0 f_0(x) + w_1 f_1(x) + \\cdots + w_n f_n(x) + b$ for time data $(x_t, y_t)$. More precisely, it finds the coefficients $w_i$ and $b$ that optimize the approximation:\n",
    "\n",
    "$$ \\begin{bmatrix} y_0 \\\\ y_1 \\\\ \\vdots \\end{bmatrix} \\approx \\begin{bmatrix} f_0(x_0) & f_1(x_0) \\\\ f_0(x_1) & f_1(x_1) & \\cdots \\\\ \\vdots & \\vdots \\end{bmatrix} \\begin{bmatrix} w_0 \\\\ w_1 \\\\ \\vdots \\end{bmatrix} + b \\begin{bmatrix} 1 \\\\ 1 \\\\ \\vdots \\end{bmatrix}$$\n",
    "\n",
    "The approximation above is specifically for functions $f: \\mathbb{R} \\rightarrow \\mathbb{R}$, but it generalizes to data of arbitrary dimensions.\n",
    "\n",
    "We could use SINDy to fit functions based on input/output data from a trained neural network. The main two questions are:\n",
    "1. What is the best way to gather data from a trained neural network?\n",
    "2. What sets of functions $f_i$ can we use to give us useful information? The $f_i$ functions should be independent of each other otherwise there would be infinite best-fit models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mmetbo-rdIRi"
   },
   "source": [
    "## Fitting Polynomials\n",
    "\n",
    "An obvious choice of library functions is powers of the input ($x$, $x^2$, ...) which would give us polynomial models. We could then compare the resulting polynomial model with known polynomial approximations for common functions (e.g. Maclaurin series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "FRyr2eJWVoGO",
    "outputId": "08333df0-ca2b-4d34-8094-be51cae2803a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: + 0.99x^0 + -0.98x^1 + 0.52x^2 + -0.18x^3 + 0.09x^4 + 0.00x^5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Construct data\n",
    "f = lambda x: np.exp(-x)\n",
    "xdata = np.random.uniform(low=-1.0, high=1.0, size=[100])\n",
    "ydata = f(xdata) + np.random.normal(scale=0.08, size=[100])\n",
    "\n",
    "# Fit a fifth-degree polynomial with regression\n",
    "X = np.column_stack([xdata, xdata**2.0, xdata**3.0, xdata**4.0, xdata**5.0])\n",
    "reg = sklearn.linear_model.LinearRegression()\n",
    "reg.fit(X, ydata)\n",
    "\n",
    "# Print model\n",
    "print(\"Model:\", end=\"\")\n",
    "for c, b in zip([reg.intercept_]+list(reg.coef_), range(6)):\n",
    "  print(f\" + {c:.2f}x^{b}\", end=\"\")\n",
    "print()\n",
    "\n",
    "# Plot data and model predictions\n",
    "plt.axhline(color=\"black\"); plt.axvline(color=\"black\")\n",
    "plt.scatter(xdata, ydata)\n",
    "plt.scatter(xdata, reg.predict(X))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqNmWz43fxXx"
   },
   "source": [
    "## Fitting Sinusoids\n",
    "\n",
    "Another obvious choice of library functions is sinusoids.\n",
    "\n",
    "For example, suppose we know that the data is approximately sinusoidal with angular frequency $\\omega$, then we could find a model of the form\n",
    "$$ r\\sin(\\omega x + \\psi) + b $$\n",
    "by using the library $\\{\\sin(\\omega x), \\cos(\\omega x)\\}$:\n",
    "\n",
    "$$ r \\sin(\\omega x + \\psi) + b = w_0\\sin(\\omega x) + w_1\\cos(\\omega x) + b $$\n",
    "\n",
    "We would just need to convert the cartesian coordinates $w_0, w_1$ into polar coordinates $r,\\psi$:\n",
    "\n",
    "$$ r = \\sqrt{w_0^2 + w_1^2} \\qquad \\psi = \\begin{cases} \\cos^{-1}(w_0/r) & w_1 \\ge 0 \\\\ 2\\pi - \\cos^{-1}(w_0/r) & w_1 < 0 \\end{cases} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "kaBtbUwa0em0",
    "outputId": "c70c144a-9cf6-4108-da58-7507bf084756"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 0.37sin(x) + 0.35cos(x) + 0.21\n",
      "Model: 0.51sin(x + 0.76) + 0.21\n",
      "Model R^2 value: 0.98\n",
      "<matplotlib.collections.PathCollection object at 0x7fd74b8980d0>\n",
      "<matplotlib.collections.PathCollection object at 0x7fd74b80f450>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df3xU9Zno8c8zkwkMoImaVJoEC9ta7rXKShvZ3iWvdq9I0VUhZbdRaUtby7K9tsXVXjC0vRi43ZLCvf7Al9zKolus7Wp0NY3aLkXpdhe2bgnFouhSqbZLQqkgJBYTyCTz3D9mJkxmzplkMieZX8/79eJFcuZkzjdinnzPc57v8xVVxRhjTOHzZXsAxhhjxocFfGOMKRIW8I0xpkhYwDfGmCJhAd8YY4pESbYH4KaiokKnT5+e7WEYY0xe2bt373FVrXR6LWcD/vTp02lvb8/2MIwxJq+IyG/dXrOUjjHGFAkL+MYYUyQ8CfgicrWIHBSRQyLS6PD6RSLyExHZJyL7ReTPvbiuMcaYkcs44IuIH7gfuAa4BLhJRC5JOO3rQIuqzgZuBDZnel1jjDHp8WKGPwc4pKqvq2of8CiwKOEcBc6NflwGHPHgusYYY9LgRZVONXA47vMO4E8SzmkCfiwiXwYmA1c5vZGILAeWA1x00UUeDC03tO7rZOP2gxzp6qWqPMjKBTOpn12d7WEZY4rMeD20vQn4jqrWAH8OfFdEkq6tqltUtVZVaysrHctI807rvk5WP/kSnV29KNDZ1cvqJ1+idV9ntodmjCkyXgT8TmBa3Oc10WPxPg+0AKjqz4CJQIUH1855G7cfpDc0MORYb2iAjdsPZmlExphi5UVKZw9wsYjMIBLobwSWJJzzn8A84Dsi8l+JBPxjHlw75x3p6k3reCJLBxljvJLxDF9V+4EvAduBV4lU4xwQkXUisjB62leAvxKRXwL/AHxWi2TnlaryYFrH41k6yBjjJU9y+Kr6Q1V9v6q+V1X/Nnpsjaq2RT9+RVXnquofq+rlqvpjL66bD1YumEkw4B9yLBjws3LBzGG/1tJBxhgv5WwvnUIRS7+MJi2TaTrIGGPiWcAfB/Wzq0eVd68qD9LpENx9IsxofNZy+saYtFjAT5NXD1FH8j4rF8xk9ZMvJaV1BqKPP2I5fcCCvjFmWNY8LQ1ePUQd6fvUz65m/eLLqC4PIoBfJOm9LKdvjBkpC/hp8OohajrvUz+7mt2NV/JG87WEXQqbLKdvjBkJC/hp8Oohqtv5nV29Ke8WMinxNMYYC/hpGHXAfeZ2WHs+NJXB2vP5P8GHXU9NlSLKpMTTGGPsoW0anB6iDhtwn7kd2h88+7kOsJh/4sLSDqZzlGo5zgA+fIQ5ohVs6G+gqc3n+EA3kxJPY4yRXF3wWltbq17taetlewLH9/LvhufXQXcHlNXAvDUwqyHyBWvPBx1Ieh8Fkh/Bwhn1EyLAZE4DcEKnsJ7PUvfxWyywG2OGJSJ7VbXW8bVCD/ixipjEWfn6xZdlFkD3t0SD/GEioTvuv2MgCNdvigT9prLRXyMqrPCU72r+4s7HMn4vY0xhK+qAP7d5p+PipfJggMkTStKf9e9vgR/dAb0nUp9XNg1ue5nw2vPwaXiUoz9LFWTS+XDNt87ePRhjTIJUAb/gc/huFTFdvSG6ekNAGguY9rfA0ysgNIKqnO4OAJ7iYyzWfyK+hF4VHErqUxIh8kvm6RWRA3FBPz7NVD4pgCp094Ysx2+MGaLgq3RGWrI4onr659eNLNhDJJcP/M/epTw8cBX96kMV+tXHv4Y/QI+Wjux9EoV64akvQFM53H0pe9oeGLKI62RP5BdZbEHXbY+9yNdbXxrdtYwxBaXgA75TKaObYevpo7P2YQWCkQe3RH7h3Nl/M+878wgzznyf9515hKWhr7EhcEsk7QMg0fEFzwffCMaqA4BC92Eu/cX/Yv7AT91PBR554T+Z3vgsc5t3WmtlY4pYwQf8xPYE1eVBzpsUcDx32LuB6KzdSVgjfyibdvaBLe6185dfuxxuexmauuHOE5G/73gD6r8NpZNH/P0FOcOqkpYRnWv99I0pbgX/0NbJqCt3HHL4qnCSKTSFlrL33PnsbrzS8Xppl4WO9OEwEFbhj858b9jzYqrLg47jNMbkv6Ku0nEz6tr8/S30/GgNE3uOckQvYEN/A23husHCzGqP6/zvueQ1rvj1fZF0kvgca/pP6BR6dCJVcnxw8VZbuM71GgK80XztqMZnjMltFvDHQCwwd3b1Jlbhj7rOf9g7D6cqIV+AAQW/hgYP9WgpjaFlrkHfZvjGFK5UAb/gc/hjJdbFsro8SOKvzNG2LB62i+ashsjzgbJpgET+nnDOkGAPMEn6+Grp40Dyal7rvWNM8Sr4OvxhDa6YdWiLMAJebkM4ovea1TB0fE3ljl8zlWP8ZuISzgTKWK+fY9upOY6pKy/bThhjcltxB/zEFEn3YceFTam4bUM4mpbFo3qvsppoewdnE0LdNPnup2nJB2DW2bx9675OmtoODC4+A9tBy5hCV7wpnf0tkQVMiQupQr2RGf8IedmyeFTvNW9NpO4/lXBoyPcUe1YQH+xjbActYwpXcc7wYzN7h4oXYOQLrMDTlsWjeq/YnchgIzcX3Yfh7kth3ho2bq9IelYQz3bQMqYwFWeVzt2Xpg6O0cZneWe47wsgEOTWdz7HD1KUbVoVjzH5y6p0EqWawce1Rcg789aAf5gePaFeVkcreJxYFY8xhat4Av7+lsgMuKk8soDJifiHtEXIO7MaYNH9kZ48KVzIMf6y9N+Sjp83KZD5PgHGmJzlSQ5fRK4G7gX8wFZVbXY4pwFoIrJG6ZequsSLa49IYjWOU+4+ftOSfBZftumS4hGgObCVKaUlruWaxpjCk3EOX0T8wK+A+UAHsAe4SVVfiTvnYqAFuFJVT4rIu1T1zVTv62UOP7RuKoGww4NI8YOGR1V/nxeG69+fr88qjDGuxjqHPwc4pKqvq2of8CiwKOGcvwLuV9WTAMMFey/9/r4FlAy4BDwN07roAHPPbGLG9ycXXvvg2MpcN2lUIxlj8p8XAb8aiM8bdESPxXs/8H4R2S0iL0RTQElEZLmItItI+7FjxzIf2f4W3vXWC667S/UEpw7ZPCSX2ge37utkbvNOZmTax35Ww9m++4nEN7iRCvtH1mLZGJO/xuuhbQlwMfBnwE3A34lIUk8AVd2iqrWqWltZWZn5VZ9fl9RL5uy1YEPohtS9a7IktjDKs19Ebouz4jZS4ekVFvSNKXBeBPxOIH4KWRM9Fq8DaFPVkKq+QSTnf7EH104tRcoiLMK2U3McX8v2wqNhm6ila1YDey5by1EqCavQ7/TPnuYKY2NM/vEi4O8BLhaRGSJSCtwItCWc00pkdo+IVBBJ8bzuwbWdxUowk/pYRqjCz8+vd+1RM5o+OF7ysiEbRO4Ylu55Dx8+fS9/dOZ7+DTsfGL3YZvlG1PAMg74qtoPfAnYDrwKtKjqARFZJyILo6dtB94SkVeAnwArVfWtTK/t6Jnb4cnlritOVeFfwx/g5mM38t//S6VnfXC85PUvosQ7hiNa4X6ypXaMKVie5PBV9Yeq+n5Vfa+q/m302BpVbYt+rKp6u6peoqqXqeqjXlw3yf4WaH8Ip5m9KnSEK7g1dAtLQ1+jNzTAT/7jWNJ+t7mw8MjLhmyQfGewob+BHnVZkWupHWMKVmE1T3t+Ha5pHIS6vqElike6eqmfXZ31AJ/Iy4ZskNx2uS1cByG4t3Sz80NtK9c0piAVVsBPEaiO6AVJx7Kdq0/Fy19EKxfMTNo6cYf/o/QGn2JS7+8cvkIHO2sW3GI0Y3JZhhsyDaegeun0BKc6HlfgHm4cciwXcvXjpX52tWPqatI169x76VuppjHjK7YyvvswY1UuXVAz/A2hG1ilm5kkfYPHwgpP+a6m7uO38LMi3srP+Y5hmF76sXy+zfKNGXvPr3PfkMmjn8GCCvjbTs3hhK+PVSUtVMlbHNEL2NDfQFu4DnnsRarKg9x9w+VFFeiHFWu21lSO4/MPy+cbM/b2t7jvZeHhz2BBBfyq8iBtXXW09SVv7hG/YhVsz9YkbnvjltWM/1iMKSaxVI6LnuBUJnl0qYLK4TuVMybKhdYJOWneGvr9E4cc6vdPzN/NYIzJF06pnKgeLWVD6AbPLlVQAT/x4aSbbLdOyEWtA3NpDC2jI1xBWIWOcAWNoWW0DszN9tCMKWwuKRtVaAwtc20BMxoFldKBoTXsnS6BPZfLMbNl4/aDdPb9KU/wp0OOT3l2C/X//I9jViZmTDFq3dc5uM7mZxMrmEpyd+BOraAtXEe1h/GqoGb4MLTTpJNiKsdMh9Ndz0LfLlaFNo9pmZgxxSaxG+43+z5Bb8LK9x4tZUN/g+fxquACvlOnyZhcaZ2Qi5zuelaVtAwpcQWs9YIxGdq4/SDzB37KrtIVvD5hCatKWmgZ+AhHqUQRjlLJ6tAy9p473/N4VXApHbf8vAC7G68c38HkEafVuFXi0t/OSjWNGbXat3ewPrB1cDJVI8f5hPwLq/uWce831zOVyAbhY6HgZvi52vI41zmtxu0ufZfjuW4rmo0xw1td+njSnfMk6WN16eNjfu2CC/hed5osJvWzq9ndeCVvNF/L7sYruVdvSuqq6XWZmDHF5kKOp3XcSwUX8N36xljePn3bTs1xLNX0skzMmGIjLosZ3Y57qeBy+OBtp8li5rZy2csyMWOKzrw1kWq3+MVWgeC4LHIsuBm+8Y6lx4wZA7Ma4PpNUDYNkMjf128al/UtBTnDN95IuRHLGPftNqagxZoWRrXu62Rj884x7+Yrqs47RGVbbW2ttre3Z3sYxkms2VPcLWm/fyLfkC+w7dQcyoIBRKCrJ1SUraiNSUdsIVZ8SXQw4B/1s0cR2auqtU6vWUrHpM+h2VPJwGmW9T2CAl29IU72hIZ0KG3d15mVoRqT65wWi45Vk0cL+CZ9Lguv3BZqWYdSY9y5LRYdiyaPFvBN+lzKx5z2DR58zTqUGuNoPBeLWsA36XPonR9r9uTGVjob42w8q+Es4Ju0OfXObw9fzF2Bb/PGhCUcmvAp1pY8NHi+lXIa4248F4talY5J29zmnUPaT68teYil/ueQuF1nFPhu/1U8MOWLVqVjzDhKVaVjdfgmbYn5+E/6dw4J9hDpTrqkZCfnLthkwd6YHGEpHZO2xHy8n7DjeX4NW0mmMTnEk4AvIleLyEEROSQijSnO+wsRURFxvN0w+SHxIdNAiv+N5g/81EoyjckRGQd8EfED9wPXAJcAN4nIJQ7nnQPcCvx7ptc02ZX4kOkHvo/h9CRIBO4JbOavT90/3kM0xjjwIoc/Bzikqq8DiMijwCLglYTz/jfwLWClB9c0WTa0I+m18MztaPuDJKTy8Ql8quS5SDsG67VjTFZ5kdKpBg7Hfd4RPTZIRD4ITFPVZ1O9kYgsF5F2EWk/dix5F3eTw667C5LCfYQPbB9cY3LAmD+0FREfcBfwleHOVdUtqlqrqrWVlZVjPTTjsZQbONg+uMZknRcBvxOYFvd5TfRYzDnApcA/i8hvgA8DbfbgtgDNW4PbLN+tHYMxZvx4EfD3ABeLyAwRKQVuBNpiL6pqt6pWqOp0VZ0OvAAsVFVbVVVoZjVA7c0kBf1x2s3HGJNaxgFfVfuBLwHbgVeBFlU9ICLrRGRhpu9v8sx1d8HiLWd38wmeDyVBeHI53H1p5OGtMSYrrLWCGTsOG6UQCI7bdm7GFCPbAMVkh8NGKYR6rWLHmCyxXjrGE637OpP3vnWrzOk+bHX5xmSBzfBNxmJ7cnZ29Q7Z1vBk4F3uX/T0CsvnGzPOLOCbjLntybm25y/p0VLnL7LUjslX+1siBQhN5XlXiGApHZMxt+0LWwfmElbl3sDmpPbJgC3GMvnnmduh/SGIdY/qPhy5W4W8SFHaDN9kzG37Qr8IbeE6OrXC+QttMZbJJ/tbhgb7mDy6W7WAbzLmtifnTX8yjWDAz4b+hqTUTq+Wsue9Xx7PYRqTmR/dQVKwj8mTu1VL6ZiMxbpmJlXpzK6m9j3n85WWMIRgVUkLVfIWR/QCNvQ3sPeVi9ltS/NMPtjfAr0n3F/Pk7tVW3hlxtyMxmed++UDbzRf61zSadsimlxy96WRfL0jiawuz5Ecvi28MlnlluOvKg+6lnTatogmp7ikbBQi/aNyJNgPxwK+GXNuOf6VC2a6lnTatogmp7ikbE7qFFqrh+38njMs4Jsxl7glYnV5kPWLL6N+drVrSafbcWOyYt4aepkw5FCPltIUWppXkxN7aGvGxdAtEc+qKg/S6RDc3dJAxmTFrAbueHRfUuFBW7gOyaPJiQV8k1UrF8xk9ZMvDUnrxNI9xuSK1n2dPB2uo62vLum18kmBLIxodCylY7IqVbrHmFyxcftBtwp8Tp3uz5siA5vhm6yr9++mfsI6mNgBE2rYc/jLzN1+sZVpmuzZ3xJZPdvdAWU11L59PZ0kz+4BQmFl4/aDefH/qAV8k12Jm6R0H+ZDe1exfOAq7uTmwTJNIC9+oEz+iq0HqX17B82lDxLkTOSF7sM0lz6I9kFb2Dno50uRgaV0THY5bJLiE/i0/zkW+nYBVqZpxl78epCVJS1ng31UkDPcEXDvipkvRQYW8E12uSxo8UmkFUNMvsygTH6KXw9SJccdz6mStygPJj+gzaciAwv4JrtS9CCpkrfOfpwnMyiTn+InFEdcurv+ngpevPNj3HPD5XlbZGA5fJNd89bAk8tx6kJ4RC8A8msGZfJTVXmQD729I1pnf5ywRu4yY3q0lPWhT3Av7mtK8oHN8E12zWqI9CJh6A4pYSK31i9MvJWHr/ht3v6AmfxwzyWv8a3AVmp8x/FJJNiHFVShI1xBY2gZ7efOz/YwM2YzfJN9190FF304WgZ3GBB8KAhM5RhTX7oTpp+XNw2qTP654tf3gfQNOeaTSLCv69tEMOBnfQHcZdoM3+SGWQ1w28tQNo183lHI5CmX1sdV8lbe5elTsRm+yS1uOwflyY5CJg/tbyGSUkx+juQrr2H3bVeO+5DGis3wTW5xq9rJkx2FTB56fh3OWxdKpKiggHgS8EXkahE5KCKHRKTR4fXbReQVEdkvIs+LyHu8uK4pQPPWQCChBDMQLLgfPJNDXO8eteCeG2Uc8EXED9wPXANcAtwkIpcknLYPqFXVWcATwIZMr2sK1KwGuH5TNJcvkb+v3zTkB691Xydzm3cyo/FZ5jbvzJvGVSY39QSnuhx/9ziPZOx5kcOfAxxS1dcBRORRYBHwSuwEVf1J3PkvAJ/y4LqmUM1qcJ1ZxZbAx1ZFWq8dk6kNoRtYpZuZFFel06OlbAjdQFP2hjUmvEjpVAPxj7g7osfcfB74kQfXNcVif0tkE+mmcj78g48yf+CnQ162XjsmE9tOzaExtIyOcAVhlcG6+22n5mR7aJ4b1yodEfkUUAt81OX15cBygIsuumgcR2ayLdapMKklckI3zakcozmwFUJDOxdarx0zWlXlQdq6kjc3qS7Adh5ezPA7gWlxn9dEjw0hIlcBXwMWquqZxNcBVHWLqtaqam1lZaUHQzP5IL5ToXI2TdO6r9Oxm+Yk6RvSWA2s144ZvZULZhIM+IccK9R2Hl7M8PcAF4vIDCKB/kZgSfwJIjIbeAC4WlXf9OCapoDEdyqMiaVp6k87V1DEN1Yr1B9O4z3XO0lwPV5IMg74qtovIl8CtgN+4CFVPSAi64B2VW0DNgJTgMdFBOA/VXVhptc2hcEtHXOkqxcurHFcBfmmVCBQ0D+cxlvDPfAvhv+HPMnhq+oPgR8mHFsT9/FVXlzHFKaq8iCdDkG/qjxafx+/IxZAIMjU67/JG7OuHcdRmny3cftB5g/8lFWlkY6YR7SCDf0NbNxeWhTBHmylrckBKXOoI6jLN2Ykat/eQXNcR8wa33GaA1upfXtHtoc2bqyXjsm6YXOoKeryjRmp1aWPM4mhHTEnSR+rSx8H1mdnUOPMAr7JCWnlUPe3RFspd0R67MxbY78QzLAuxHnrQrfjhchSOia/xOryuw8DGvn76RXRjofGuBOXBnxuxwuRBXyTXxzq8q1fvhkRa8xnKR2TZ6xfvhmh5Jr7udRfv6mo04EW8E3Oi//B/dnECqZyLPmkIrotN8NzrblfPJf6217O8uiyx1I6Jqcltl34Zt8n6NXSoScV2W25GV6s5n5X6Qpen7CEXaUrmD/w06JvsmcB3+S0xLYLbeE67ggt4yiVWF2+cWM1984spWNymlPbhbZwHU+fruONZltpa5xZzb0zm+GbnObWBdO6Y5pUrObemQV8k9OKqXWt8Y7V3DuzgG9yWv3satYvvozq8iBCZFOK9YsvK5pmV2aUrObekeXwTc4rlta1ZnTiy3Y/M+XnrAo8xqTeoxA8D0qC0HuyKGvunVjAN8bkrfh6+4W+XXw1tIXS/v7Ii70nwF8Ki7cUfaCPsZSOMSZvxZftNgUeplT6h54w0Ac/uiMLI8tNFvCNMXkrvmz3PE45n9R7YpxGk/ss4Btj8lZVeZCFvl3sKl2R7aHkBcvhG2Nyntvm4/dc8hp/vHdLcionzplAGRPGcay5zAK+MSanpdx8/NVmSBXs1c96/RxN4zHQPGApHWNMTkvspwTQGxqINEJzyc+rQke4gpWhv2bbqTnjMcy8YDN8Y0xOc+qnNHh8ovvX1fVtAiKL9UyEBXxTNNzywCa3VZUH6XQI+gp0cQ7l/CHptRM6BbA2HIkspWOKQmJf/VgeuHVfZ7aHZobh1E8pZk3fp+nToa/14Wdd/1Jrw+HAZvimKKTKA1tAyG2xf5+N2w8mzfTbwnUQgq+WPs5UjkNZDaXz1nCvrax1ZAHfFIWUeWCT82L9lGY0Psv1vl2sKmmhSo5zRCvY0N/Ah0/fiwBVE4OsHJhJfbYHnKMspWOKQvwCndiWdwt9u1BgbvNOS+3kmNZ9ncxt3smMxmeH/Pt8ZsrP2Rh4YMhOVhsDDwz+W3Z29XLbYy8yPeHrTIQnAV9ErhaRgyJySEQaHV6fICKPRV//dxGZ7sV1jRmpey55jW85bHm30LfL8vk5JtXzltXy90yQoam5CTLAnSUPD36u0b/t3zVZxgFfRPzA/cA1wCXATSJyScJpnwdOqur7gLuBb2V6XWPSccWv7yMoyVvefTPwEBDJ5ze1HcjG0EyCVM9bJoS6Hb/mfHHuozNYr28Ab2b4c4BDqvq6qvYBjwKLEs5ZBGyLfvwEME9ExINrGzMy3R2OhydzmrUlkaDf1Ruy2WAO8Pp5iz2nOcuLgF8NHI77vCN6zPEcVe0HuoELEt9IRJaLSLuItB87dsyDoRkT5bblncAn/TsHP7fZYPY57Ve80LeLn0281fVrTjIlrfcrVjn10FZVt6hqrarWVlZWZns4ppDMWzOY203kJzz4sc0Gsy+x7n6hbxffCmxlKs6TwAEJsCmwDIDEtIEtvBrKi4DfCUyL+7wmeszxHBEpAcqAtzy4tjEjM6shLqwnW+jbBdhsMBck7mP81dLHk56/DCqbhv/jm2n6+lp+03wtd99wue1/nIKous17RvgGkQD+K2AekcC+B1iiqgfizvkicJmqfkFEbgQWq2rKlRG1tbXa3t6e0diMiffw1/+CT/ufw+npUVjhH3Q+kz9+rwWIXNNUDo73ZwJNXeM9mpwnIntVtdbptYwXXqlqv4h8CdgO+IGHVPWAiKwD2lW1DXgQ+K6IHAJOADdmel1j0vXAlC+ip2CpQ9D3CSyRHYh/N2CrNMdSqp5Gjq+V1UD34eQ3cnkuY9xlPMMfKzbDN16L1Xcf8N2Az61GrGwa3PbyuI6rmCT2todInn394ssAHF97+IrfcsVLd0Io7vlKIAjXb7LNyR2M6QzfmHwRm0W++YNK1weAbuWbxhspe9tHP4bIM5VY+4Q3f1EJtUvgtR9H/n3KamDeGgv2o2AB3xSdb5d8kjWhe5xn+ZYmGFMjqbFf6NtFc2Ark6IPaqdyDH75fZvReyCnyjKNGUuxdMJ3Ts3huwNXEU7MZgaCkZmjGTNuVVBV5cHB11aVtAwG+0GhXnh+3VgPr+BZwDdFIz6dcGf/zfxN6BY6whWEkUju3maQY86pt32sVj72WpUcd/5iS7dlzFI6pmgkphPawnW09dUhwBtN1yadbztkeS++t73Tf9fqw88Q/oUPn9OqCUu3ZcwCvikablvlOaUZEqtJYp0XAQv6GYr1tk+yvyVSjeMU7C3d5glL6ZiikSqdkGi4ahIzBp5fN7T0Mkb8lm7ziM3wTdEYLp0Qz3bI8t6wKTK3HL2GLdh7xAK+KSqu6YQE6aR/zPBGlCKzFbVjzlI6xjhYuWAmf1n6b0O2RFwU3R3Lts5L34hSZPPWRHL18Sx37ymb4RvjoN6/m+sCWykZOA1AjRxnfWArGoK2rjp7gJumEaXIYmmb59fZitoxYgHfGCfPrxsM9jGTpI9VJS209dUNzk4t4I/MiFNksxoswI8hS+kY48TlAWKVnN3GwR7gjlw6FVJm7NgM3xgnLg8Qj+jZnTntAe7IpVMhNRxbEDd61h7ZGCf7W+DpFUPqwmM/KgP4eEzn2WYpo7W/ZdR5+lTtle3fIiJVe2RL6RjjZFZDZLFPWWT3TiWy4bkIlEiYJb4d1Hf+3+yOMR/FfpF2HwY08vfTKyLHR8AWxGXGAr4xbmY1RDZDEX/S5tgCsPc74z+mfOe0mjaNTpi2IC4zFvCNGY4OuB+/+9IRz06LReu+TuY272RG47ND1yzsb3FeWAUj7oSZqr2yGZ49tDVmOOJ3D/rdh+n/wZf5RtsBtp2aU/QPEd1W1FYffibaGM3FCFfTrlww0zGHb9U+I2MB35jhfOiz0P6g68slA6dZFn6E7zCnKLtqxlfN+EQYSCgE6Q0NMO0XGwGXtEsaq2m9rPYpRlalY8xIPHN7JGfvMtNXhVtDt9AWrhs8Vl0EwcipasbJ6xOWuG8cv/jvbLGVh6xKx5gMtVZ/hbkTnqAjXOH4ugjcE9jM2pKHBo/FZvuF3HfHqWrGyZtS6fxC2TQL9uPIAr4xw4jNYju7etnQ30CPljqe5xP4tAEPJ1MAAAuqSURBVP85Fvp2DR7rDQ2w9ukD4zXUcTeS6phgwM/hD660xmg5wAK+McOIn8W2hetoDC3DLRPqE2gKPDzk2MmeUMHO8ktLUoeQ8yYFWL/4Mq5Y+Ndx6xpsD+FssYBvzDCc9sLtVOfUDsB5nBoyywcKcmFQ675OzvQ7bEcY53Qo7vXYuoamrsjfFuzHnQV8Y4bhVOO9ob/BaedVIJLPvzewmV2lKwYDfyEuDHL6Jba25CF+PeGTvDFhCW9MWMIe31JefHZLFkZnnFjAN2YYTp0ed/g/SgsLXFM7IlDjO05zYCsLfbsKcmFQ4i+xtSUPsdT/HH7RwTYUU+QMXw/da4vTckRGAV9EzheRHSLyWvTv8xzOuVxEfiYiB0Rkv4jckMk1jRlv9bOrWb/4MqrLgwiRcsv1iy9j9enPcEKnpPzaSdJHU+C7BbkwKPGX2Cf9OxGH0ssS0RG3TjBjK9MZfiPwvKpeDDwf/TxRD7BUVT8AXA3cIyLlGV7XmHFVP7ua3Y1X8kbztexuvJL62dVUlQdZ27/UtWon5jz5A/X+3eM00vETu/NZW/IQhyZ8Cr9rkosRt04wYyvTgL8I2Bb9eBtQn3iCqv5KVV+LfnwEeBNwKco1Jn+sXDCTHf6P0hhaRke4wj29A/DUFwourVE/u5pn/ugplpY8R4mEHWf3g2wj8pyQacC/UFV/F/34KHBhqpNFZA5QCvza5fXlItIuIu3Hjh3LcGjGjL2JAR9t4Trq+jbxVVmB67p1HUirDXC+eO9vH0vqJJqoH7F6+xwxbMAXkedE5GWHP4viz9NIjwbX/99F5N3Ad4HPqarjvZ+qblHVWlWtray0mwCTu2KLsU72hM4eG5hLX6DM/YtCvQUz02/d10nTN+7ErTWLauTPKZ3AV/r+h5Vg5ohhm6ep6lVur4nI70Xk3ar6u2hAf9PlvHOBZ4GvqeoLox6tMTnCbSOO9RM+R1PggeSe7zGxmT6MOghme4u/1n2d7HpqM82yOWUaZ8aZ7wORh9wmN2Sa0mkDPhP9+DPADxJPEJFS4CngYVV9IsPrGZMT3Orqt52aA9dvIiwpfrRCvfDkX42ql358mwclO/16Xnx2C+tkCyXi/pD2HSYA1ro412Qa8JuB+SLyGnBV9HNEpFZEtkbPaQA+AnxWRF6M/rk8w+sak1UpN+KY1cA6/4phq3fS3d4PvN3iz3WjkmEs63uESdLn+roCXwt9frB8tZC7heabjPrhq+pbwDyH4+3AsujHjwCPZHIdY3JJ675Oevr6k47Hz2a3nZrDCV8fdwW+nXImPLi93wjTO15t8ee2UQkM38e/yvdWilcFqb2Ze69bn9Z4zPiwlbbGpMHpYS1AeTAwZDZbVR6kLVzH7aEvjGCmP/Iada+2+MvkTuF0cKrj8bD4YPEWuO6utMZixo8FfGPS4Nb/ffKEkiEz49iipFh3zVR1+mcC53K06X2E7yzjaNP72NP2gOv1ndo8jCZPnsmdwqRr1tHvnzjkWL9/Ir6PP2DVODnOAr4xaRhpoIxvx/B0uI4bJv0d7R/akNQTfkBKkL53mMoxfAJTOcale7/uGvTd2jykmydPeaewvyXyQLmp3PnB8qwGShbdN6TVccmi+yzY5wHb4tCYNMxt3kmnQ9CvLg+yu/HK4d9gf0skZ9/dAWU1dHV3Uc4fkk47SiVTmw4BY1OG6bQ1YTDg5+ErfhvZbDy+rDQQtN71ecS2ODTGI5mmVFoH5jL3zCZmnP4ec89s4lxNDvYA79LjkfPHqAzT7U7hil/fl7yGIPZg2eQ9m+Ebk6bRzridZtW7SldQ4zuedG4X51BeVk64u4Mj4QvY0N+QtEH6iO4o0qRN5YjDgnlFkKYuz69nvJdqhp9RWaYxxah+dnVaKZXYLwinVNCG/gaaA1uH1LX3aQnn+Hqh+w/4iPTVvyewmXvYzBGtYEN/A0931SW9V9oS0kvMW8PvqWAqyX2sIsdNvrOUjjFjKD4l4yRWxXOUSsIqHKUSLZ2MX4fW+fsk8icW/F+eeLP7Q9WR2N8SWfTVfRjQwUVgP+7/46Qy0h4tZX3fJ9K/hsk5NsM3Zgy5lXHG23vufKY2RhYqTYVIIE/BJzCZ05FPug9D6y3wozug9yQEz4P+MxB6J/J6YDKUTIDeEyD+SC+fsmnQ945jrv5jJb+ksW8Zq0paqJK3OKKRdNLec+eP4rs3ucYCvjFjaLi6dqcHvj3BqUzq/Z3LVzgIhyIBHc7+HRN652zw1+gvnu7Drm91IcfZ4f8obX1nU0bBgJ/11g+nIFhKx5gxlGoFrFsN/YbQDcOvzh0jUlbjSZ2/yU02wzdmDK1cMNOx3j1VEI314VlV0kK1RCp4Uu4m5ZVAEOatoX5Weg+lTf6wGb4xY2g0K2NjfXjq+jYx48z3eXjgKsJjUT0dPH/IallbXFX4rA7fmBzjVK+/0Ldr8EHqSZ2MiHCenOJEeDLnyGlKJbl7Z0q2erZgWR2+MXkkNvuPLe7yidAWrhvyIBXO7iT1obd3DP4y6GIyAQ0xRc4AkY1I+ghQzinC+PAT5ndSQedlq7jCgn3RsRm+MTluRuOzjptFC3D3DZcn3Q2MxHDPEUz+sl46xuSxVJ0t458RpGO0u2SZ/GYB35gcN1zDtvrZ1exuvJJ0C3nS3SXL5D8L+MbkuJFW+qS761W655v8Zw9tjckDI2nY5lTzH/AJAb/QExq6r+5odsky+c8CvjEFIrG6J75181hsomLyj1XpGGNMAbEqHWOMMRbwjTGmWFjAN8aYImEB3xhjioQFfGOMKRI5W6UjIseA347yyyuA4x4OZ7zl+/jBvodcYd9D9o33+N+jqpVOL+RswM+EiLS7lSXlg3wfP9j3kCvse8i+XBq/pXSMMaZIWMA3xpgiUagBf0u2B5ChfB8/2PeQK+x7yL6cGX9B5vCNMcYkK9QZvjHGmAQW8I0xpkgUVMAXkatF5KCIHBKRxmyPJ10i8pCIvCkiL2d7LKMlItNE5Cci8oqIHBCRW7M9pnSJyEQR+bmI/DL6PazN9phGQ0T8IrJPRJ7J9lhGQ0R+IyIviciLIpKXrXNFpFxEnhCR/xCRV0Xkv2V1PIWSwxcRP/ArYD7QAewBblLVV7I6sDSIyEeAU8DDqnpptsczGiLybuDdqvoLETkH2AvU59m/gwCTVfWUiASAXcCtqvpCloeWFhG5HagFzlXV67I9nnSJyG+AWlXN20VXIrIN+FdV3SoipcAkVe3K1ngKaYY/Bzikqq+rah/wKLAoy2NKi6r+C3Ai2+PIhKr+TlV/Ef34D8CrQF7ttKERp6KfBqJ/8mpmJCI1wLXA1myPpViJSBnwEeBBAFXty2awh8IK+NXA4bjPO8izQFNoRGQ6MBv49+yOJH3RdMiLwJvADlXNt+/hHmAVEB7uxBymwI9FZK+ILM/2YEZhBnAM+Ptoam2riEzO5oAKKeCbHCIiU4B/BP5GVd/O9njSpaoDqno5UAPMEZG8SbGJyHXAm6q6N9tjyVCdqn4QuAb4YjTlmU9KgA8C/09VZwPvAFl9tlhIAb8TmBb3eU30mBln0bz3PwLfU9Unsz2eTERvwX8CXJ3tsaRhLrAwmgN/FLhSRB7J7pDSp6qd0b/fBJ4ikrbNJx1AR9zd4RNEfgFkTSEF/D3AxSIyI/pw5EagLctjKjrRB54PAq+q6l3ZHs9oiEiliJRHPw4SKQT4j+yOauRUdbWq1qjqdCI/BztV9VNZHlZaRGRy9KE/0TTIx4C8ql5T1aPAYRGZGT00D8hq8UJJNi/uJVXtF5EvAdsBP/CQqh7I8rDSIiL/APwZUCEiHcCdqvpgdkeVtrnAp4GXojlwgK+q6g+zOKZ0vRvYFq388gEtqpqXpY157ELgqcj8gRLg+6r6T9kd0qh8GfhedBL6OvC5bA6mYMoyjTHGpFZIKR1jjDEpWMA3xpgiYQHfGGOKhAV8Y4wpEhbwjTGmSFjAN8aYImEB3xhjisT/B54fcrdHP6h8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Construct data\n",
    "f = lambda x: 0.5*tf.sin(x + 0.79) + 0.2\n",
    "xdata = tf.random.uniform([100], minval=0.0, maxval=math.pi * 2.0)\n",
    "ydata = f(xdata) + tf.random.normal([100], stddev=0.05)\n",
    "\n",
    "# (x,y) -> (r,theta)\n",
    "def cart2polar(x, y):\n",
    "  r = math.sqrt(x**2.0 + y**2.0)\n",
    "  theta = math.acos(x/r) if y >= 0.0 else 2*math.pi - math.acos(x/r)\n",
    "  return [r,theta]\n",
    "\n",
    "# Fit regression against our basis {sin(x), cos(x)}\n",
    "# to get w0, w1, b\n",
    "X = np.column_stack([tf.sin(xdata), tf.cos(xdata)])\n",
    "reg = sklearn.linear_model.LinearRegression()\n",
    "reg.fit(X, ydata)\n",
    "w0, w1 = reg.coef_\n",
    "b = reg.intercept_\n",
    "\n",
    "# Output model equation in two different forms\n",
    "# Plot data and model predictions\n",
    "print(f\"Model: {w0:.2f}sin(x) + {w1:.2f}cos(x) + {b:.2f}\")\n",
    "r, theta = cart2polar(w0, w1)\n",
    "print(f\"Model: {r:.2f}sin(x + {theta:.2f}) + {b:.2f}\")\n",
    "print(f\"Model R^2 value: {reg.score(X, ydata):.2f}\")\n",
    "print(plt.scatter(xdata, ydata))\n",
    "print(plt.scatter(xdata, reg.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7ypzwuy3ks5"
   },
   "source": [
    "Alternatively, suppose we know our data is sinusoidal, but don't know the angular frequency $\\omega$:\n",
    "\n",
    "$$ f(x) = \\sin(\\omega x) $$\n",
    "\n",
    "To find the angular frequency, we could use Fourier analysis. The Fourier transform of a pure sine wave will be zero everywhere except for at the frequency of the wave:\n",
    "\n",
    "$$ \\hat{f}(\\xi) = \\int_{-\\infty}^{\\infty} f(t)\\cos(2\\pi\\xi t)\\ dt - i\\int_{-\\infty}^{\\infty} f(t)\\sin(2\\pi\\xi t)\\ dt $$\n",
    "\n",
    "We are not interested in calculating values of the Fourier transform, but only in discovering frequencies where $\\hat{f}$ is large. This means we can integrate on a finite interval instead of over all real numbers:\n",
    "\n",
    "$$ g(\\xi) = \\int_{0}^{L} f(t)\\cos(2\\pi\\xi t)\\ dt - i\\int_{0}^{L} f(t)\\sin(2\\pi\\xi t)\\ dt $$\n",
    "\n",
    "The function $g$ converges to $\\hat{f}$ as the range of the integration increases. But importantly, even if the range is small, the value of $n$ that maximizes $g$ should be approximately the same $n$ value that maximizes $\\hat{f}$.\n",
    "\n",
    "$$ \\max_{\\xi}|g(\\xi)| \\approx \\max_{\\xi}|\\hat{f}(\\xi)| $$\n",
    "\n",
    "Now we have the correspondence:\n",
    "\n",
    "$$ g\\left( \\frac{n}{L} \\right) = \\frac{L}{2} (a_n - ib_n) $$\n",
    "\n",
    "where $a_n$ and $b_n$ are the coefficients of the Fourier series expansion of $f$:\n",
    "\n",
    "$$ f(x) = a_0 + \\sum_{n=1}^{\\infty} \\left[ a_n\\cos\\left(\\frac{2\\pi nx}{L}\\right) + b_n\\sin\\left(\\frac{2\\pi nx}{L}\\right) \\right] $$\n",
    "\n",
    "$$ a_n = \\frac{2}{L}\\int_0^{L} f(x)\\cos\\left( \\frac{2\\pi nx}{L} \\right)\\ dx $$\n",
    "$$ b_n = \\frac{2}{L}\\int_0^{L} f(x)\\sin\\left( \\frac{2\\pi nx}{L} \\right)\\ dx $$\n",
    "\n",
    "So, we want to find\n",
    "\n",
    "$$ \\max_{\\xi} \\left| g\\left(\\xi\\right)\\right| = \\frac{L}{2}(a_{L\\xi}^2 + b_{L\\xi}^2) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "3YLoWS1I6OLx",
    "outputId": "5ec833cd-cc15-4dd8-cc23-b1aefc92003d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest frequency: 2.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: complete this demo\n",
    "# Construct data\n",
    "f = lambda x: np.sin(2.1*x)\n",
    "xdata = tf.random.uniform([100], minval=0.0, maxval=math.pi * 2.0)\n",
    "ydata = f(xdata) + tf.random.normal([100], stddev=0.05)\n",
    "\n",
    "# Fit a regression using a basis of sinusoids\n",
    "X = np.column_stack([np.sin(n*0.5*xdata) for n in range(1,11)]\\\n",
    "                  + [np.cos(n*0.5*xdata) for n in range(1, 11)])\n",
    "reg = sklearn.linear_model.LinearRegression()\n",
    "reg.fit(X, ydata)\n",
    "\n",
    "# Find largest coefficient\n",
    "i_of_largest_coef = np.argmax(reg.coef_)\n",
    "print(\"Closest frequency:\", 0.5*(i_of_largest_coef+1))\n",
    "\n",
    "# Estimate the frequency\n",
    "\n",
    "\n",
    "# Plot data and model predictions\n",
    "plt.axhline(color=\"black\"); plt.axvline(color=\"black\")\n",
    "plt.scatter(xdata, ydata)\n",
    "plt.scatter(xdata, reg.predict(X))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFk57ovx_80X"
   },
   "source": [
    "## Multivariable Inputs\n",
    "\n",
    "So far, I have only really considered neural networks that learn a function $f: \\mathbb{R}\\rightarrow \\mathbb{R}$. However, a network trained on the MNIST dataset is a function $f: \\mathbb{R}^{784} \\rightarrow \\mathbb{R}^{10}$. What are the consequences of this increased dimensionality?\n",
    "\n",
    "Well, increasing the output dimensionality shouldn't be too difficult to handle because we can just consider each output individually. For MNIST, we could start by just examining the first output that detects the digit '0'.\n",
    "\n",
    "Large input dimensions may be a little more challenging. If the goal is to find a mathematical representation of $f$ that is more concise than the neural network itself, then there is little point in finding a function $f$ that is dependent on all 784 input variables (not to mention the combinations of those input variables). We need a way of systematically eliminating terms that are unimportant. Can we define a process such as the following:\n",
    "\n",
    "* repeat:\n",
    "  1. Fit data against a set of basis functions $B$\n",
    "  2. Eliminate unimportant basis functions\n",
    "  3. Identify new basis functions that may be significant and add them to $B$.\n",
    "\n",
    "The third step is the most difficult. To start, we could just naively consider every basis function to be possibly significant. We could start with $B = \\{x_1, x_2, ..., x_{784}\\}$ and find a linear fit, eliminate terms with small coefficients, then add $\\{x_1^2, x_1 x_2, x_1 x_3, ..., x_1 x_{784}\\}$, and so on. However, it would be nice to have a way of determining which basis functions are most likely to be significant by using the model from the previous iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9suONCK45lu"
   },
   "source": [
    "**Idea 1**: _the functions in $B$ should only be compositions of basis functions from the $B$ of the previous iteration._\n",
    "\n",
    "For example, we could start by fitting a linear regression against $B=\\{x_1, x_2, x_3, x_4\\}$. Suppose we find out that the coefficients on $x_3$ and $x_4$ are negligible. Then our next set of basis functions could be $B = \\{x_1, x_2, x_1^2, x_2^2, x_1 x_2\\}$ only constructed from the previously significant functions. The problem is that if the coefficient on $x_3$ is close to zero, that doesn't mean $x_3$ is unimportant, it just means that _on average_, the output doesn't change with respect to $x_3$.\n",
    "\n",
    "**Idea 2**: _find ways of representing compound functions using sums of other functions_\n",
    "\n",
    "For example, a function of the form $a\\cos(x) + b\\sin(x)$ can always be rewritten in the form $r\\sin(x + \\psi)$ via a simple cartesian->polar coordinate conversion. Fourier series and Taylor series are also techniques for doing this, but prevent their own challenges:\n",
    "* While there are algorithms to convert functions into polynomials, sinusoids, etc (Maclaurin series, Fourier analysis), there are not general algorithms to convert back to the original functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5-4EKOyudwY"
   },
   "source": [
    "# Applying SINDy to MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dF49LEdAf3JY"
   },
   "outputs": [],
   "source": [
    "# Function definitions for this section\n",
    "\n",
    "def constructModel():\n",
    "  \"\"\"Builds a 4-layer neural network, trains it on MNIST data,\n",
    "  prints information, saves the model to a file, returns model\"\"\"\n",
    "  (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "  x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "  x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "  # Build and compile model\n",
    "  inputs = keras.Input(shape=(784,))\n",
    "  hiddl1 = keras.layers.Dense(183, activation=\"relu\")(inputs)\n",
    "  hiddl2 = keras.layers.Dense(57, activation=\"relu\")(hiddl1)\n",
    "  outputs = keras.layers.Dense(10, activation=\"relu\")(hiddl2)\n",
    "  model = keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")\n",
    "  model.summary()\n",
    "  model.compile(\n",
    "      loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "      optimizer=keras.optimizers.RMSprop(),\n",
    "      metrics=[\"accuracy\"],\n",
    "  )\n",
    "\n",
    "  # Fit data, print test results\n",
    "  model.fit(x_train, y_train, batch_size=64, epochs=3, validation_split=0.2)\n",
    "  test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "  print(\"Test loss:\", test_scores[0])\n",
    "  print(\"Test accuracy:\", test_scores[1])\n",
    "  model.save(\"mnist_model.h5\")\n",
    "  print(\"Saved model to mnist_model.h5\")\n",
    "  return model\n",
    "\n",
    "def getDataForDigit(digit, model=None):\n",
    "  \"\"\"\n",
    "  Returns (x_data, y_data)\n",
    "  x_data: numpy array (10000, 784)\n",
    "  y_data: numpy array (10000,)\n",
    "  If model is `None` then it is loaded from file\n",
    "  \"\"\"\n",
    "  _, (x_data, _) = keras.datasets.mnist.load_data()\n",
    "  x_data = x_data.reshape(10000, 784).astype(\"float32\") / 255\n",
    "  if not model:\n",
    "    model = keras.models.load_model(\"mnist_model.h5\")\n",
    "  y_data = model.predict(x_data)\n",
    "  y_data = np.array([y[digit] for y in y_data])\n",
    "  return x_data, y_data\n",
    "\n",
    "def linearRegression(X, y_data):\n",
    "  \"\"\"Returns the regression object that results from\n",
    "  fitting the given data\"\"\"\n",
    "  reg = sklearn.linear_model.LinearRegression()\n",
    "  reg.fit(X, y_data)\n",
    "  return reg\n",
    "\n",
    "def showAsImages(pixeldatalist, titles=None):\n",
    "  \"\"\"\n",
    "  Displays `len(pixeldatalist)` images, each 28x28 pixels\n",
    "  \"\"\"\n",
    "  pixeldatalist = [np.array(item) for item in pixeldatalist]\n",
    "  f, axes = plt.subplots(1, len(pixeldatalist))\n",
    "  for i, axis in enumerate(axes):\n",
    "    axis.imshow(pixeldatalist[i].reshape(28, 28), cmap=\"gray\")\n",
    "    if titles:\n",
    "      axis.set_title(titles[i])\n",
    "  f.set_size_inches(8, 8)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3UXXIU74dp5s",
    "outputId": "4bb7fc59-aae1-47e5-9ce0-f01f1d2fb4b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 183)               143655    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 57)                10488     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                580       \n",
      "=================================================================\n",
      "Total params: 154,723\n",
      "Trainable params: 154,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "750/750 [==============================] - 3s 3ms/step - loss: 0.6764 - accuracy: 0.7927 - val_loss: 0.3750 - val_accuracy: 0.8652\n",
      "Epoch 2/3\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.3495 - accuracy: 0.8722 - val_loss: 0.3411 - val_accuracy: 0.8720\n",
      "Epoch 3/3\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.3102 - accuracy: 0.8827 - val_loss: 0.3237 - val_accuracy: 0.8779\n",
      "313/313 - 0s - loss: 0.3129 - accuracy: 0.8826\n",
      "Test loss: 0.3129315972328186\n",
      "Test accuracy: 0.8826000094413757\n",
      "Saved model to mnist_model.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x7f0a843a0370>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constructModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aJRDTBf4moS"
   },
   "source": [
    "## Linear Model\n",
    "\n",
    "First thing we could try is just fitting a linear model to our network data for any given digit. For any digit (output node), we can treat the network as a function $\\mathbb{R}^{784} \\rightarrow \\mathbb{R}$ by ignoring the other nine output nodes. The code below finds the best linear fit for the specified digit and displays the coefficients associated with each pixel. Black indicates a negative weight while white indicates a positive weight.\n",
    "\n",
    "We will evaluate the model based on the coefficient of determination ($R^2$ value) and based on compositionality (number of terms in the equation). We can see that only being linear, our model already has an $R^2$ of 0.8, but hopfully introducing non-linearity will improve the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "LCcs9oA-hxgN",
    "outputId": "02e1e831-3947-4718-c0a1-ced1741d9964"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression results for digit '0'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 1.4778\n",
      "Lowest weight -20871.75 is at pixel 670\n",
      "R^2: 0.8038\n"
     ]
    }
   ],
   "source": [
    "digit = 0\n",
    "\n",
    "x_data, y_data = getDataForDigit(digit)\n",
    "reg = linearRegression(x_data, y_data)\n",
    "\n",
    "print(f\"Regression results for digit '{digit}'\")\n",
    "showAsImages([reg.coef_, tf.nn.sigmoid(reg.coef_)], [\"Weights\", \"$\\\\sigma$(Weights)\"])\n",
    "print(f\"Intercept: {reg.intercept_:.4f}\")\n",
    "print(f\"Lowest weight {reg.coef_.min():.2f} is at pixel {reg.coef_.argmin()}\")\n",
    "print(f\"R^2: {reg.score(x_data, y_data):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahdpUYdM1j7B"
   },
   "source": [
    "Since a major goal is reducing compositionality, and since dealing with 784 input parameters is a little cumbersome, we need a way of elimitating some pixels entirely. One strategy is to prioritize pixels based on their variance in the dataset. For the MNIST images, most of the pixels along the edge of the image are black no matter which image we look at, so these pixels have a variance of zero and should not be included in our mathematical model.\n",
    "\n",
    "Intuitively, if we are building a progressively more complex equation, we should add the pixels with the **highest variance first**. This could possibly be extended to **terms with high variance** instead of just input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "S5IGeUyPX-Lx",
    "outputId": "6ccc692d-3e6e-4c53-83dc-e7bacf91fbf9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max pixel variance is 0.2009 at pixel 378\n",
      "Max pixel average is 0.5606 at pixel 435\n"
     ]
    }
   ],
   "source": [
    "x_data, _ = getDataForDigit(0)\n",
    "\n",
    "pixel_averages = np.average(x_data, axis=0)\n",
    "pixel_variances = np.var(x_data, axis=0)\n",
    "\n",
    "showAsImages([pixel_averages, pixel_variances], [\"Pixel Averages\", \" Pixel Variances\"])\n",
    "\n",
    "print(f\"Max pixel variance is {pixel_variances.max():.4f} at pixel {pixel_variances.argmax()}\")\n",
    "print(f\"Max pixel average is {pixel_averages.max():.4f} at pixel {pixel_averages.argmax()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph below shows how the accuracy of the equation increases as more pixels are included in the linear model. Pixels with higher variance in the input space are added before low-variance pixels. The graph confirms our expectations that the marginal benefit of adding a single pixel decreases as the number of pixels already in the equation increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "X08Cty8kbvCV",
    "outputId": "5e1254d2-fabf-4a9a-9767-4729b68c9cc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show how linear model gets better as more pixels are added.\n",
      "Pixels with highest variance are added first.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_data, y_data = getDataForDigit(0)\n",
    "\n",
    "pixel_variances = sorted(enumerate(np.average(x_data, axis=0)), key=lambda pair: pair[1], reverse=True)\n",
    "\n",
    "r2vals = []\n",
    "for numpixtoinclude in range(1, 200):\n",
    "  includeinreg = [x_data[:,pair[0]] for pair in pixel_variances[:numpixtoinclude]]\n",
    "  X = np.column_stack(includeinreg)\n",
    "  reg = linearRegression(X, y_data)\n",
    "  r2vals.append(reg.score(X, y_data))\n",
    "\n",
    "print(\"Show how linear model gets better as more pixels are added.\")\n",
    "print(\"Pixels with highest variance are added first.\")\n",
    "axis = plt.figure().add_subplot(111)\n",
    "axis.set_ylim([0, 1])\n",
    "axis.plot(range(1, 200), r2vals)\n",
    "axis.set_xlabel(\"# pixels\")\n",
    "axis.set_ylabel(\"$R^2$\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Quadratic Terms\n",
    "\n",
    "Here, we will start to construct some Python infrastructure for dealing with data and mathematical equations together. We will introduce a `pruneByVariance` function on equations which removes terms with low variance in the input space. The output of the following code first shows the best fit linear equation of the top ten high-variance terms and its accuracy (0.45). The equation is then augmented with the quadratic terms built from those ten inputs and prunned back down to ten terms. Four of the original linear terms were replaced with quadratic terms which increased the accuracy to 0.51."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 94
    },
    "id": "bMzrIzu1g1Px",
    "outputId": "f2a56777-2412-4116-fc97-f3b5e877666d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$-3.07x_{378} + -0.44x_{406} + 1.05x_{627} + -0.07x_{437} + -2.46x_{409} + -0.48x_{461} + -0.58x_{433} + -1.93x_{462} + 0.50x_{628} + -1.23x_{464}$\n",
      "0.44579526260682245\n",
      "$-10.66x_{378} + -3.53x_{409} + -3.54x_{462} + -4.21x_{461} + 6.96x_{378}x_{378} + 4.27x_{406}x_{409} + 2.47x_{627} + 4.60x_{461}x_{462} + -1.85x_{406}x_{437} + -2.35x_{627}x_{409}$\n",
      "0.5052866163968938\n"
     ]
    }
   ],
   "source": [
    "class Term:\n",
    "  def __init__(self, name, data):\n",
    "    self._name = name\n",
    "    self._data = data\n",
    "    self._coef = None\n",
    "    self._var = None\n",
    "  def __lt__(self, other):\n",
    "    return self._coef < other._coef\n",
    "  def __eq__(self, other):\n",
    "    return self._coef == other._coef\n",
    "  def __repr__(self):\n",
    "    if self._coef == None:\n",
    "      return f\"\\\\_{self._name}\"\n",
    "    return f\"{self._coef:.2f}{self._name}\"\n",
    "  def __mul__(self, other):\n",
    "    return Term(self._name+other._name, self._data*other._data)\n",
    "  def getVariance(self):\n",
    "    if self._var != None: return self._var\n",
    "    self._var = np.var(self._data)\n",
    "    return self._var\n",
    "  def getCoefMag(self):\n",
    "    return np.abs(self._coef)\n",
    "\n",
    "class Equation:\n",
    "  def __init__(self, terms=None):\n",
    "    self._terms = []\n",
    "    self.rsquared_ = None\n",
    "    self.intercept_ = None\n",
    "  def fitTerms(self, y_data):\n",
    "    X = np.column_stack([t._data for t in self._terms])\n",
    "    reg = sklearn.linear_model.LinearRegression()\n",
    "    reg.fit(X, y_data)\n",
    "    for i, c in enumerate(reg.coef_):\n",
    "      self._terms[i]._coef = c\n",
    "    self.rsquared_ = reg.score(X, y_data)\n",
    "    self.intercept_ = reg.intercept_\n",
    "  def pruneByVariance(self, remaining):\n",
    "    self._terms = sorted(eq._terms, key=Term.getVariance, reverse=True)[:remaining]\n",
    "  def pruneByCoef(self, remaining):\n",
    "    self._terms = sorted(eq._terms, key=Term.getCoefMag, reverse=True)[:remaining]\n",
    "  def pruneByVarTimesCoef(self, remaining):\n",
    "    keyFunc = lambda t: t.getCoefMag()*t.getVariance()\n",
    "    self._terms = sorted(eq._terms, key=keyFunc, reverse=True)[:remaining]\n",
    "  def display(self):\n",
    "    print(\"$\"+\" + \".join([t.__repr__() for t in self._terms])+\"$\")\n",
    "    #display(Latex(\"$\"+\" + \".join([t.__repr__() for t in self._terms])+\"$\"))\n",
    "\n",
    "x_data, y_data = getDataForDigit(0)\n",
    "\n",
    "# Get top linear terms\n",
    "eq = Equation()\n",
    "for i, singlepixeldata in enumerate(x_data.T):\n",
    "  eq._terms.append(Term(\"x_{%d}\" % i, singlepixeldata))\n",
    "eq.fitTerms(y_data)\n",
    "eq.pruneByVariance(10)\n",
    "eq.fitTerms(y_data)\n",
    "eq.display()\n",
    "print(eq.rsquared_)\n",
    "#eq.pruneByVariance(5)\n",
    "\n",
    "# Add quadratic terms (build from the linear terms)\n",
    "quadTerms = []\n",
    "for i, t1 in enumerate(eq._terms):\n",
    "  for t2 in eq._terms[i:]:\n",
    "    quadTerms.append(t1*t2)\n",
    "eq._terms += quadTerms\n",
    "\n",
    "eq.fitTerms(y_data)\n",
    "eq.pruneByCoef(10)\n",
    "eq.fitTerms(y_data)\n",
    "eq.display()\n",
    "print(eq.rsquared_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmBXTRtObrAE"
   },
   "source": [
    "---\n",
    "\n",
    "# Maclaurin Series Approximations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63HvRf4ETACx"
   },
   "source": [
    "## Linear Functions\n",
    "\n",
    "The first step toward approximating polynomials is approximating linear functions. At first glance, this may seem unnecessary since a neural network's feedforward mechanism is primarily linear to begin with. However, the non-linear activation function is precisely the reason this section is still important. Here, I detail how a neural network can model a linear function even when non-linear functions are used in the computation.\n",
    "\n",
    "The network we will build has one input node, one output node, and one hidden node. Consider any activation function $a(x)$ with a non-zero derivative at $x=0$. No matter the function $a$, Taylor's Theorem allows us to rewrite (a portion of) $a$ as an infinite polynomial.\n",
    "\n",
    "$$ a(x) = \\sum_{n = 0}^{\\infty} \\frac{a^{(n)}(0)}{n!} x^n \\qquad \\text{(Taylor's Theorem)} $$\n",
    "\n",
    "First, replace $x$ with $hx$ where $h$ is positive. We will eventually consider what happens when $h$ approaches zero.\n",
    "\n",
    "$$ a(hx) = \\sum_{n = 0}^{\\infty} \\frac{a^{(n)}(0)}{n!} (hx)^n $$\n",
    "\n",
    "Now rewrite this equation by isolating the linear term on the left.\n",
    "\n",
    "$$ ha'(0) x = a(hx) - a(0) - \\sum_{n=2}^{\\infty} \\frac{h^n a^{(n)}(0)}{n!} x^n $$\n",
    "\n",
    "Isolate $x$ on the left.\n",
    "\n",
    "$$ x = \\frac{a(hx)}{ha'(0)} - \\frac{a(0)}{ha'(0)} - \\sum_{n=2}^{\\infty} \\frac{h^{n-1} a^{(n)}(0)}{a'(0)n!} x^n $$\n",
    "\n",
    "If we consider the limit as $h \\rightarrow 0$, the summation drops out because $h^{n-1}$ will vanish for any $n \\ge 2$. We are left with:\n",
    "\n",
    "$$ x = \\lim_{h \\rightarrow 0} \\frac{a(hx) - a(0)}{h a'(0)} $$\n",
    "\n",
    "Let's introduce some constants so we can rewrite the equation to see the correspondence with a neural network.\n",
    "\n",
    "$$ x = \\lim_{h \\rightarrow 0} \\left( W_1 a(W_0 x + B_0) + B_1 \\right) $$\n",
    "\n",
    "| - layer - | - - - - weight - - - - | - - - - - - bias - - - - - - |\n",
    "| --------: | :-----------------: | :--------------: |\n",
    "| first  | $W_0=h$                | $B_0 = 0$        |\n",
    "| second | $W_1=\\frac{1}{ha'(0)}$ | $B_1 = -W_1 a(0)$ |\n",
    "\n",
    "This equation and table shows that we can approximate the identity function with arbitrary accuracy using just one hidden node (i.e. one application of the non-linear function $a$). An arbitrary linear function can be approximated by adjusting the second-layer weight and bias.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cANPfqXTEy1V"
   },
   "source": [
    "## Approximating $x^2$\n",
    "\n",
    "The same general process to approximating linear functions can be applied to approximating quadratic polynomials as well. As before, start with Taylor's Theorem and isolate the desired degree of $x$ on the left (in this case $x^2$).\n",
    "\n",
    "$$ x^2 = \\frac{2a(hx)}{h^2 a^{(2)}(0)} - \\frac{2a(0)}{h^2 a^{(2)}(0)} - \\frac{2a'(0)x}{h a^{(2)}(0)} - \\frac{2}{h^2 a^{(2)}(0)}\\sum_{n=3}^{\\infty} \\frac{h^n a^{(n)}(0)}{n!} x^n $$\n",
    "\n",
    "If we consider the limit as $h \\rightarrow 0$, the sum term drops out because $h^n / h^2$ will always approach zero for any $n \\ge 3$. We are left with the following:\n",
    "\n",
    "$$ x^2 = \\lim_{h \\rightarrow 0} \\left( \\frac{2}{h^2 a^{(2)}(0)}a(hx) - \\frac{2a(0)}{h^2 a^{(2)}(0)} - \\frac{2a'(0)}{h a^{(2)}(0)}x \\right) $$\n",
    "\n",
    "Notice that this formula has an $x$ (all the way to the right) that does not go through an activation function. We can subsitute this $x$ for the linear approximation in the section above. Notably, the expression will now be a multivariate limit, so rename the two limit variables $h_2$ and $h_1$ where $h_1$ is the variable from the linear (degree 1) approximation. Interestingly, this limit does not exist (it evaluates differently depending on how $(h_1, h_2)$ approaches $(0,0)$). However, if $h_1 = h_2^2$, then we get the result we want:\n",
    "\n",
    "$$ x^2 = \\lim_{h \\rightarrow 0} \\frac{2}{h^2 a^{(2)}(0)} \\left( a(hx) - \\frac{a(h^2 x)}{h} - \\frac{(h-1)a(0)}{h} \\right) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnwP2bYajFEO"
   },
   "source": [
    "## Approximating $x^2$ (Second approach)\n",
    "\n",
    "This approach is a little cleaner than the above approach, we still start with Taylor series, but we use the fact that even powers of $x$ are even functions.\n",
    "\n",
    "$$ a(hx) = \\sum_{n = 0}^{\\infty} \\frac{a^{(n)}(0)}{n!} (hx)^n \\qquad \\text{(Taylor's Theorem)} $$\n",
    "\n",
    "$$ a(-hx) = \\sum_{n = 0}^{\\infty} \\frac{a^{(n)}(0)}{n!} (-hx)^n \\qquad \\text{(Taylor's Theorem)} $$\n",
    "\n",
    "If we add these two equations together, we can get every odd term to drop out.\n",
    "\n",
    "$$ a(hx) + a(-hx) = \\sum_{n = 0}^{\\infty} \\left( \\frac{h^n a^{(n)}(0)}{n!} x^n + \\frac{(-1)^n h^n a^{(n)}(0)}{n!} x^n \\right) $$\n",
    "\n",
    "$$ a(hx) + a(-hx) = \\sum_{n = 0}^{\\infty} \\frac{2 h^{2n} a^{(2n)}(0)}{(2n)!} x^{2n} $$\n",
    "\n",
    "Now separate out the first two terms of the sum.\n",
    "\n",
    "$$ a(hx) + a(-hx) = 2 a(0) + h^2 a^{(2)}(0) x^2 + \\sum_{n = 2}^{\\infty} \\frac{2 h^{2n} a^{(2n)}(0)}{(2n)!} x^{2n} $$\n",
    "\n",
    "Isolate $x^2$\n",
    "\n",
    "$$ x^2 = \\frac{a(hx)}{h^2 a^{(2)}(0)} + \\frac{a(-hx)}{h^2 a^{(2)}(0)} - \\frac{2 a(0)}{h^2 a^{(2)}(0)} - \\frac{1}{a^{(2)}(0)} \\sum_{n = 2}^{\\infty} \\frac{2 h^{2n-2} a^{(2n)}(0)}{(2n)!} x^{2n} $$\n",
    "\n",
    "Consider the limit as $h \\rightarrow 0$. The sum term drops out. Factor out common terms, and we are left with:\n",
    "\n",
    "$$ x^2 = \\lim_{h \\rightarrow 0} \\frac{a(hx) + a(-hx) - 2a(0)}{h^2 a^{(2)}(0)} $$\n",
    "\n",
    "This expression converges much faster than the previous method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhY8_n_sT5rT"
   },
   "source": [
    "## Approximating $x^d$\n",
    "\n",
    "The process for approximating $x^2$ can be repeated, this time for a general degree $d$. This time, we require that $a^{(d)}(0) \\neq 0$. From Taylor's Theorem, isolate the desired power on the left. The $n$ in the sum iterates from zero to infinity, but skips $d$.\n",
    "\n",
    "$$ x^d = \\frac{d!a(hx)}{h^d a^{(d)}(0)} - \\frac{d!}{h^d a^{(d)}(0)}\\sum_{n\\neq d} \\frac{h^n a^{(n)}(0)}{n!} x^n $$\n",
    "\n",
    "Once again, consider the limit as $h \\rightarrow 0$. All of the terms in the sum where $n > d$ are going to approach zero leaving us with a finite sum.\n",
    "\n",
    "$$ x^d = \\lim_{h \\rightarrow 0} \\left( \\frac{d!}{h^d a^{(d)}(0)} a(hx) - \\sum_{n = 0}^{d - 1} \\frac{d! h^{n-d} a^{(n)}(0)}{n! a^{(d)}(0)} x^n \\right) $$\n",
    "\n",
    "Introduce constants:\n",
    "\n",
    "$$ x^d = \\lim_{h \\rightarrow 0} \\left( A a(hx) - \\sum_{n = 0}^{d - 1} B_n x^n \\right) $$\n",
    "\n",
    "$$ A = \\frac{d!}{h^d a^{(d)}(0)} \\qquad B_n = A h^n a^{(n)}(0) $$\n",
    "\n",
    "Written a different way:\n",
    "\n",
    "$$ x^d = \\lim_{h \\rightarrow 0} \\left( A a(hx) - \\sum_{n = 0}^{d - 1} B_n (hx)^n \\right) $$\n",
    "\n",
    "$$ A = \\frac{d!}{h^d a^{(d)}(0)} \\qquad B_n = A a^{(n)}(0) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pw-_Hw-ibhuE"
   },
   "source": [
    "---\n",
    "\n",
    "# Change-of-Basis Approximation Strategy\n",
    "\n",
    "This section describes a general strategy for approximating any function $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ with a neural network using an arbitrary activation function $a$ (with certain restrictions) to any desired accuracy using a single hidden activation layer. The basic idea is to find a representation of $f$ as a linear combination of various functions of the form $a(hx + k)$. For a more concrete example, see [Using Maclaurin Approximation](#scrollTo=iZycguIdbhuG).\n",
    "\n",
    "Start with:\n",
    "* $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ the function to be approximated\n",
    "* $a: \\mathbb{R} \\rightarrow \\mathbb{R}$ an activation function\n",
    "* A function basis $\\mathcal{F}$, for example:\n",
    "  * polynomials $\\{1, x, x^2, ...\\}$\n",
    "  * sinusoids $\\{1, \\sin(x), \\cos(x), \\sin(2x), \\dots\\}$\n",
    "* A methodology for producing an approximation $f_{app}$ of $f$ using finite subsets of the basis $\\mathcal{F}$\n",
    "  * Maclaurin series (requiring $f_{app}^{(n)}(0) = f^{(n)}(0)$ for some values $n \\ge 0$)\n",
    "  * Point Sampling (requiring $f_{app}(n) = f(n)$ for some values $n$)\n",
    "  * Matching Integrals (requring $\\int_R f^{(n)}_{app}(x)\\ dx = \\int_R f^{(n)}(x)\\ dx$ for some values $n \\ge 0$)\n",
    "  * Remez Algorithm\n",
    "  * Fourier series\n",
    "\n",
    "General process:\n",
    "1. Find an approximation $f_{app}$ of $f$ that is a linear combination of $d$ vectors in $\\mathcal{F}$.\n",
    "2. Construct a set of independent functions $\\mathcal{A} = \\{a(h_0 x + k_0), a(h_1 x + k_1), \\dots, a(h_d x + k_d) \\}$\n",
    "3. Construct a basis $\\mathcal{B}$ of approximations of the functions in $\\mathcal{A}$ where $\\mathcal{B}_i \\approx \\mathcal{A}_i$\n",
    "4. Construct a change of basis matrix $B = \\begin{bmatrix} \\mathcal{B}_0 & \\mathcal{B}_1 & \\cdots & \\mathcal{B}_d \\end{bmatrix}$ that converts from $\\mathcal{B}$-coordinates to $\\mathcal{F}$-coordinates.\n",
    "5. Find the coordinates of $f_{app}$ in $\\mathcal{B}$ by inverting the change of basis matrix: $\\text{coords}_{\\mathcal{B}}(f_{app}) = B^{-1}\\ \\text{coords}_{\\mathcal{F}}(f_{app})$\n",
    "\n",
    "The numbers in $\\text{coords}_{\\mathcal{B}}(f_{app})$ are the weights coming out of the neurons in the hidden layer of the network. The weights and biases fed _into_ the hidden layer neurons are the $h,k$ values from step 2.\n",
    "\n",
    "There are two approximations happening: the approximation of $f$ and the approximation of $a$. Both approximations are represented in the same finite-dimensional subspace of $\\mathcal{F}$, meaning the transformation from one to the other is a finite linear operator.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZycguIdbhuG"
   },
   "source": [
    "## Using Maclaurin Approximation\n",
    "\n",
    "Here is an example of applying the above approximation strategy using Maclaurin series approximation and the standard basis for $d$-degree polynomials for $\\mathcal{F}$.\n",
    "\n",
    "To start, we will use $\\mathcal{A} = \\{a(0), a(hx), a(2hx), \\dots, a(dhx)\\}$\n",
    "\n",
    "The approximations $\\mathcal{B}$ will be found using the first $d$ terms of the Maclaurin expansion.\n",
    "\n",
    "$$ \\mathcal{A}_j = a(khx) \\approx \\sum_{n=0}^{d} \\frac{j^n h^n a^{(n)}(0)}{n!} x^n = \\mathcal{B}_j $$\n",
    "\n",
    "Now construct the change of basis matrix $B$. The columns of $B$ are the vectors in $\\mathcal{B}$ written with respect to the standard polynomial basis $\\{1, x, x^2, \\dots, x^d\\}$. Note that $a^{(i)}(0) \\ne 0$ for $0 \\le i \\le d$ otherwise the matrix will not be invertible.\n",
    "\n",
    "$$ B = \\begin{bmatrix} \\mathcal{B}_0 & \\mathcal{B}_1 & \\cdots & \\mathcal{B}_d \\end{bmatrix} $$\n",
    "\n",
    "$$ B_{i,j} = \\frac{j^i h^i a^{(i)}(0)}{i!} $$\n",
    "\n",
    "Multiplying by $B$ on the left will convert coordinates with respect to $\\mathcal{B}$ into standard basis coordinates. Both coorinate vectors are column vectors. $p$ is the $d$-degree polynomial approximation of $f$.\n",
    "\n",
    "$$ B\\ \\text{coords}_{\\mathcal{B}}(p) = \\text{coords}(p) $$\n",
    "\n",
    "To get the new coordinates with respect to $\\mathcal{B}$, simply multiply the standard coordinates by the inverse of $B$.\n",
    "\n",
    "$$ \\text{coords}_{\\mathcal{B}}(p) = B^{-1} \\text{coords}(p) $$\n",
    "\n",
    "Our neural network function that approximates $p$ is\n",
    "\n",
    "$$ p(x) = \\lim_{h \\rightarrow 0} \\left( \\text{coords}_{\\mathcal{B}}(p) \\cdot a(\\begin{bmatrix} 0 & hx & 2hx & \\cdots & dhx \\end{bmatrix}^t) \\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xM6d_EqrbhuI",
    "outputId": "38db6b5a-a8ab-4ab0-b584-219e59384574"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -25.07715296],\n",
       "       [  97.79126971],\n",
       "       [-151.51657341],\n",
       "       [ 122.7842585 ],\n",
       "       [ -50.69813563],\n",
       "       [   8.5754747 ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns an approximation for poly\n",
    "# poly is a list [b0, b1, b2, ...] representing b0 + b1x + b2x^2 + b3x^3 + ...\n",
    "# a_derivs is the list [a(0), a'(0), a''(0), ...]\n",
    "# h should be close to zero (0.1 usually works well)\n",
    "# returns the coefficients [c0, c1, c2, ...] such that\n",
    "# c0 a(0) + c1 a(hx) + c2 a(2hx) + ... approximates poly\n",
    "def getApprox(poly, a_derivs, h):\n",
    "  degree = len(poly) - 1\n",
    "  # construct B matrix\n",
    "  # Note, the B matrix in the math above is actually matmul(C, B) where C\n",
    "  # is a diagonal matrix of \"row coefficients\"\n",
    "  B = []\n",
    "  for row in range(degree + 1):\n",
    "    B.append([])\n",
    "    for col in range(degree + 1):\n",
    "      B[row].append(math.pow(col, row))\n",
    "  B = np.array(B)\n",
    "\n",
    "  C_inv = []\n",
    "  for row in range(degree + 1):\n",
    "    C_inv.append([])\n",
    "    coefficient = math.factorial(row) / (math.pow(h, row) * a_derivs[row])\n",
    "    for col in range(degree + 1):\n",
    "      C_inv[row].append(coefficient if row == col else 0.0)\n",
    "  C_inv = np.array(C_inv)\n",
    "\n",
    "  # construct coords vector\n",
    "  coords = np.array(poly).reshape((degree+1, 1))\n",
    "\n",
    "  return np.matmul(np.matmul(np.linalg.inv(B), C_inv), coords)\n",
    "\n",
    "# derivatives of 1/(1+exp(-(x-1)))\n",
    "#a_derivs = [0.26894142137, 0.196611933241, 0.0908577476729, -0.0353255805162, -0.123506861366, -0.0510419761245]\n",
    "\n",
    "# derivatives of 1/(1+exp(-(5x - 1)))\n",
    "a_derivs = [0.26894142137, 0.983059666207, 2.27144369182, -4.41569756453, -77.191788354, -159.506175389]\n",
    "\n",
    "# approximate x - (1/6)x^3, a Maclaurin approx for sin(x).\n",
    "#getApprox([0.0, 1.0, 0.0, -1.0/6.0], [0.26894142137, 0.196611933241, 0.0908577476729, -0.0353255805162], 0.5)\n",
    "\n",
    "# approximates 0.5 sin(pi x) + 0.5\n",
    "# via its degree-5 maclaurin expansion\n",
    "getApprox([0.5, 1.57079632679, 0.0, -2.58385639002, 0.0, 1.27508201994],\n",
    "          a_derivs, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GOI0KLeTCy_r"
   },
   "outputs": [],
   "source": [
    "# len(inputs) = len(outputs) = d + 1\n",
    "# returns the unique d-degree polynomial p that\n",
    "# satisfies p(inputs[i]) = outputs[i] for each i.\n",
    "def getPolyApprox(inputs, outputs):\n",
    "  degree = len(inputs) - 1\n",
    "  M = []\n",
    "  for row in range(degree + 1):\n",
    "    M.append([])\n",
    "    for col in range(degree + 1):\n",
    "      M[row].append(math.pow(inputs[row], col))\n",
    "  M = np.array(M)\n",
    "\n",
    "  outputs = np.array(outputs).reshape((degree+1, 1))\n",
    "  return np.matmul(np.linalg.inv(M), outputs)\n",
    "\n",
    "def pointSampledApprox(a, p):\n",
    "  degree = len(p) - 1\n",
    "  basis = []\n",
    "  for i in range(degree+1):\n",
    "    c = i / (degree+1)\n",
    "    a_shifted = lambda x: a(5.0 * (x - c))\n",
    "    inputs = [x / degree for x in range(degree+1)]\n",
    "    outputs = [a_shifted(x) for x in inputs]\n",
    "    basis.append(getPolyApprox(inputs, outputs))\n",
    "\n",
    "  B = np.column_stack(basis)\n",
    "  print(np.matmul(np.linalg.inv(B), np.array(p).reshape((degree+1, 1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fiUdhD7EEPxb",
    "outputId": "6e57a9d6-31b9-4445-8473-fd644cc57c5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.47988103]\n",
      " [10.84523535]\n",
      " [-9.37800578]\n",
      " [-3.47771911]\n",
      " [ 5.89490843]]\n"
     ]
    }
   ],
   "source": [
    "p = getPolyApprox([0.0, 0.25, 0.5, 0.75, 1.0], [0.5, 1.0, 0.5, 0.0, 0.5])\n",
    "pointSampledApprox(lambda x: 1.0 / (1.0 + math.exp(-x)), p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7cblEvy49nJ"
   },
   "source": [
    "---\n",
    "\n",
    "# Approximating an Arbitrary Function using Convolution\n",
    "\n",
    "This section describes a neural network configuration that can approximate a real-valued function $\\mathbb{R} \\rightarrow \\mathbb{R}$ on a certain domain. The structure is inspired by signal convolution in linear systems, but it is also reminiscent of a fuzzy logic system. [Implementation](#scrollTo=x5qhSvWBw4bI) provides code for exploration and testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "H2P0q-x8JUQc",
    "outputId": "7e3bf013-8dfb-45d0-8e88-d76e51fd37ea"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"422pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 422.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-184 418,-184 418,4 -4,4\"/>\n",
       "<!-- i -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>i</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"207\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"207\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x</text>\n",
       "</g>\n",
       "<!-- o -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>o</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"207\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"207\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">y</text>\n",
       "</g>\n",
       "<!-- a -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>a</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "</g>\n",
       "<!-- o&#45;&#45;a -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>o&#45;&#45;a</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M182.7416,-153.7783C153.869,-143.7927 104.3615,-126.0365 63,-108 58.2601,-105.9331 53.2525,-103.5571 48.5278,-101.2234\"/>\n",
       "</g>\n",
       "<!-- b -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>b</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "</g>\n",
       "<!-- o&#45;&#45;b -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>o&#45;&#45;b</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M187.6918,-149.1278C168.0337,-136.0225 137.7386,-115.8257 118.1411,-102.7607\"/>\n",
       "</g>\n",
       "<!-- c -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>c</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"171\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "</g>\n",
       "<!-- o&#45;&#45;c -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>o&#45;&#45;c</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M198.2854,-144.5708C192.6253,-133.2506 185.2784,-118.5568 179.6343,-107.2687\"/>\n",
       "</g>\n",
       "<!-- d -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>d</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"243\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "</g>\n",
       "<!-- o&#45;&#45;d -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>o&#45;&#45;d</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M215.7146,-144.5708C221.3747,-133.2506 228.7216,-118.5568 234.3657,-107.2687\"/>\n",
       "</g>\n",
       "<!-- e -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>e</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"315\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "</g>\n",
       "<!-- o&#45;&#45;e -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>o&#45;&#45;e</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M226.3082,-149.1278C245.9663,-136.0225 276.2614,-115.8257 295.8589,-102.7607\"/>\n",
       "</g>\n",
       "<!-- f -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>f</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"387\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "</g>\n",
       "<!-- o&#45;&#45;f -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>o&#45;&#45;f</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M231.2584,-153.7783C260.131,-143.7927 309.6385,-126.0365 351,-108 355.7399,-105.9331 360.7475,-103.5571 365.4722,-101.2234\"/>\n",
       "</g>\n",
       "<!-- a&#45;&#45;i -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>a&#45;&#45;i</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M48.5278,-78.7766C53.2525,-76.4429 58.2601,-74.0669 63,-72 104.3615,-53.9635 153.869,-36.2073 182.7416,-26.2217\"/>\n",
       "</g>\n",
       "<!-- b&#45;&#45;i -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>b&#45;&#45;i</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M118.3082,-77.1278C137.9663,-64.0225 168.2614,-43.8257 187.8589,-30.7607\"/>\n",
       "</g>\n",
       "<!-- c&#45;&#45;i -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>c&#45;&#45;i</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M179.7146,-72.5708C185.3747,-61.2506 192.7216,-46.5568 198.3657,-35.2687\"/>\n",
       "</g>\n",
       "<!-- d&#45;&#45;i -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>d&#45;&#45;i</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M234.2854,-72.5708C228.6253,-61.2506 221.2784,-46.5568 215.6343,-35.2687\"/>\n",
       "</g>\n",
       "<!-- e&#45;&#45;i -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>e&#45;&#45;i</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M295.6918,-77.1278C276.0337,-64.0225 245.7386,-43.8257 226.1411,-30.7607\"/>\n",
       "</g>\n",
       "<!-- f&#45;&#45;i -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>f&#45;&#45;i</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M365.4722,-78.7766C360.7475,-76.4429 355.7399,-74.0669 351,-72 309.6385,-53.9635 260.131,-36.2073 231.2584,-26.2217\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Graph at 0x7fa45db0f978>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gv.Graph()\n",
    "g.node_attr[\"label\"] = \"\"\n",
    "g.node(\"i\", \"x\")\n",
    "g.node(\"o\", \"y\")\n",
    "g.edges([\"oa\", \"ob\", \"oc\", \"od\", \"oe\", \"of\"])\n",
    "g.edges([\"ai\", \"bi\", \"ci\", \"di\", \"ei\", \"fi\"])\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1MttPUnA-Ku"
   },
   "source": [
    "The network has one input node, one output node, and one hidden layer. Let $h$ denote the number of nodes in the hidden layer. The approximation becomes better as $h$ increases.\n",
    "\n",
    "Broadly, this network approximates a function by partitioning the domain of interest into $h$ equally-sized segments. The goal for any input is to get one particular node in the hidden layer to activate while the rest are deactivated. The activated node should correspond to the segment in which the input resides. The final set of weights can then easily be tuned so that the final output corresponds to the activated node according to the function being approximated.\n",
    "\n",
    "Intuitively, each hidden node \"detects\" when the input is close to a particular value. To accomplish this, an activation function $a$ should be used such that:\n",
    "\n",
    "$$a(0) = 1$$\n",
    "$$\\lim_{x \\rightarrow \\infty} a(x) = \\lim_{x \\rightarrow -\\infty} a(x) = 0$$\n",
    "\n",
    "For example, a gaussian or \"spike\" curve will suffice. Now suppose the $i$-th hidden node needs to detect when the input is near $x_i$. Then the activation $v_i$ of that node should be:\n",
    "\n",
    "$$ v_i = a(wx -wx_i) $$\n",
    "\n",
    "The weight $w$ can be varied, but the bias needs to be set so that $v_i = 1$ when $x = x_i$.\n",
    "\n",
    "If we are approximating a function $f$, then the output $y$ is given by:\n",
    "$$ y = \\sum_{i=1}^{h} v_i f(x_i) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpJhTEJEPVUv"
   },
   "source": [
    "The neural network is essentially just calculating $f$ by approximating the following equation:\n",
    "\n",
    "$$ f(x) = \\int_{a}^{b} f(\\tau)\\ \\delta(x - \\tau)\\ d\\tau \\approx \\sum_{i=1}^{h} f(i \\Delta)\\ r(x - i \\Delta) $$\n",
    "\n",
    "where $(a,b)$ is our domain of interest, $\\Delta = (b - a)/h$, $r(0) = 1$, and $r(x) = 0$ for $x \\ge h$ or $x \\le -h$.\n",
    "\n",
    "If we substitute the computation for $v_i$ into the equation for $y$, we can see the similarity:\n",
    "\n",
    "$$ y = \\sum_{i=1}^{h} f(x_i)\\ a(wx - wx_i)$$\n",
    "\n",
    "If we let $x_i = i\\Delta$ and $a(wt) = r(t)$, then the correspondence becomes complete.\n",
    "\n",
    "$$ y = \\sum_{i=1}^{h} f(i\\Delta)\\ a(w \\cdot (x - i\\Delta))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5qhSvWBw4bI"
   },
   "source": [
    "## Implementation\n",
    "\n",
    "Currently, the function being approximated is $0.5 \\sin(\\pi x)$. Change [this cell](#scrollTo=AKMcQ9OXEPdR) if you want to approximate a different function.\n",
    "\n",
    "[This cell](#scrollTo=zXPo8b9yndcO) manually sets the weights and biases of the network to the values prescribed by the theory. These are not guarenteed to be the best values (training the network afterwards does give improvements), but gives a good starting point.\n",
    "\n",
    "If the weights and biases are randomly initialized, the network probably won't learn on its own to use this approximation method. It just serves as a demonstration of how a network with one hidden layer could theoretically learn any real valued function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZR1yszCaDnkB"
   },
   "outputs": [],
   "source": [
    "# Constructs a new model called \"sinModel\"\n",
    "# MyModel(h) constructs the 3-layer network described above with h\n",
    "# nodes in the hidden layer.\n",
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, h, **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "    #self.a = lambda x: tf.exp(-x**2)   # the gaussian activation function\n",
    "    self.a = lambda x: tf.maximum(1-tf.abs(x), 0)  # sawtooth activation\n",
    "    self.w1 = tf.Variable(tf.random.uniform(shape=[1, h]))\n",
    "    self.b1 = tf.Variable(tf.random.uniform(shape=[1, h]))\n",
    "    self.w2 = tf.Variable(tf.random.uniform(shape=[h, 1]))\n",
    "    self.b2 = tf.Variable(tf.random.uniform(shape=[1, 1]))\n",
    "  def hl_act(self, i, x, **kwargs):\n",
    "    w1 = tf.reshape(self.w1[0,i], [1, 1])\n",
    "    b1 = tf.reshape(self.b1[0,i], [1, 1])\n",
    "    return self.a(tf.matmul(x, w1) + b1)\n",
    "  def __call__(self, x, **kwargs):\n",
    "    hiddenlayer = self.a(tf.matmul(x, self.w1) + self.b1)\n",
    "    return tf.matmul(hiddenlayer, self.w2) + self.b2\n",
    "\n",
    "sinModel = MyModel(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AKMcQ9OXEPdR"
   },
   "outputs": [],
   "source": [
    "# The function we want to approximate.\n",
    "# In this case, 0.5sin(pi*x)\n",
    "def f(x):\n",
    "  return 0.5 * tf.sin(math.pi * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zXPo8b9yndcO",
    "outputId": "3c5c8556-3045-4e08-a546-c4605b1f576f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(1, 1) dtype=float32, numpy=array([[0.]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually set the weights and biases to approximate f on\n",
    "# the interval [0,1]. Six sample values are used.\n",
    "\n",
    "parts = tf.constant([[0.0, 0.2, 0.4, 0.6, 0.8, 1.0]])\n",
    "w = 5.0\n",
    "\n",
    "sinModel = MyModel(6)\n",
    "sinModel.w1.assign(tf.constant([[w, w, w, w, w, w]]))\n",
    "sinModel.b1.assign(parts * -w)\n",
    "sinModel.w2.assign(f(tf.reshape(parts, (6, 1))))\n",
    "sinModel.b2.assign(tf.zeros(shape=(1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "9BCjyzJMwEa4",
    "outputId": "e99dc62b-f156-4b13-c399-26c0c83ee1f0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test: plot the model approximation and the actual function f\n",
    "x = tf.random.uniform((100, 1, 1), minval=0.0, maxval=1.0)\n",
    "y = f(x)\n",
    "y_obs = sinModel(x)\n",
    "plt.scatter(x, y, c=\"black\", s=3)\n",
    "plt.scatter(x, y_obs, c=\"red\", s=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a7YWF7kuVwi",
    "outputId": "a2f6ab76-ff38-4b0e-d0d9-c8d05610799b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa45ecaebe0>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "sinModel.compile(run_eagerly=False,\n",
    "                optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "                loss=tf.keras.losses.mean_squared_error)\n",
    "sinModel.fit(x, y, epochs=1000, batch_size=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W5KmpevavagN",
    "outputId": "c99f7be3-bd9f-4dec-826f-9af33c641958"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(1, 6) dtype=float32, numpy=\n",
      "array([[5.       , 4.999203 , 4.9981747, 5.000848 , 5.0031466, 5.       ]],\n",
      "      dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# print weights and biases\n",
    "print(sinModel.w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "3TM7e1I8-jEv",
    "outputId": "e2da51ba-9fb0-4995-8e26-371177c382e5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD7CAYAAAB68m/qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAW7UlEQVR4nO3db4xcV3nH8d/jmbgoDmTH9aIizxqH1pGw4AXJKnZUqSwNtE5exBJQ6iU7lCoai5QgJFAhKNUUDaoqU5VKqOmSnRZRFrEh8AJZIihVaVAkhFNvBITYKKkJf7wBNQavI4VggrdPX9wZ5+71/Lm7OzN37pnvRxrNn3vm3ufcmX32zLnnnmvuLgBA/m3LOgAAQH+Q0AEgECR0AAgECR0AAkFCB4BAkNABIBA9E7qZfdbMnjOzJzssNzP7tJmdMbMnzOyG/ocJAOglTQv9c5IOdVl+q6R9zdtRSfNbDwsAsFHFXgXc/VEz29ulyGFJn/foDKUTZjZhZq9x9593W++uXbt8795uqwUAJD3++OO/cPfJdst6JvQUdks6G3u+0nyta0Lfu3evlpeX+7B5ABgfZvaTTsuGelDUzI6a2bKZLZ87d26YmwaA4PUjoT8raSr2vNx87QruvuDu0+4+PTnZ9hcDAGCT+pHQj0t6T3O0y0FJz/fqPwcA9F/PPnQzW5I0I2mXma1I+ltJV0mSu39G0kOSbpN0RtKLkv5yUMECADpLM8pltsdyl/T+vkUEANgUzhQFgECQ0AEgEPlL6I2GNDUV3QMALstfQq/XpZWV6B4AcFn+EnqtJpVK0gsv0EoHgJj8JfRqVdqxQ7pwgVY6AMTkL6FLUSu9XI7uAQCS+jM51/BVq9ENAHBZPlvoAIArkNABIBAkdAAIBAkdAAJBQgeAQJDQASAQJHQACAQJHQACQUIHgECQ0AEgECR0AAgECR0AAkFCB4BAkNABIBAkdAAIBAkdAAJBQgeAQJDQASAQJHQACAQJHQACQUIHgECQ0AEgECR0AAgECR0AApEqoZvZITN7yszOmNk9bZbvMbNHzOw7ZvaEmd3W/1ABAN30TOhmVpB0n6RbJe2XNGtm+xPF/kbSg+7+JklHJP1LvwMFAHSXpoV+k6Qz7v6Mu78k6QFJhxNlXNKrmo+vlfSz/oUIAEijmKLMbklnY89XJB1IlPm4pP8wsw9I2iHprX2JDgCQWr8Ois5K+py7lyXdJmnRzK5Yt5kdNbNlM1s+d+5cnzYNAJDSJfRnJU3Fnpebr8XdKelBSXL3b0t6haRdyRW5+4K7T7v79OTk5OYiBgC0lSahn5S0z8yuM7Ptig56Hk+U+amkWyTJzF6vKKFn3wRvNKSpqegeAALXM6G7+yVJd0t6WNIPFI1mOWVmdTO7vVnsw5KqZvY9SUuS3uvuPqigU/vgB6WVlegeAAKX5qCo3P0hSQ8lXqvFHp+W9If9Da0PLl5cfw8AAQv7TNE77pAKhegeAAKXqoWeW4uL0Q0AxkDYLXQAGCMkdAAIBAkdAAJBQgeAQJDQASAQJHQACAQJHQACQUIHgECQ0AEgECR0AAgECR0AAkFCB4BAkNABIBAkdAAIBAkdAAIxngmda40CCNB4JvR6PbrWaL2edSQA0DfjmdBrNalcju4BIBBhX4Kuk2o1ugFAQMazhQ4AASKhA0AgSOgAEAgSOgAEgoQOAIEgoQNAIEjoABAIErrEVAAAgkBCl5gKAEAQSOgSUwEACAIJHQACQUKX6HIBEIRUCd3MDpnZU2Z2xszu6VDmXWZ22sxOmdkX+xvmgNHlAiAA5u7dC5gVJD0t6W2SViSdlDTr7qdjZfZJelDSH7v7qpm92t2f67be6elpX15e3mr8ADBWzOxxd59utyxNC/0mSWfc/Rl3f0nSA5IOJ8pUJd3n7quS1CuZAwD6L01C3y3pbOz5SvO1uOslXW9m3zKzE2Z2qN2KzOyomS2b2fK5c+c2FzEAoK1+HRQtStonaUbSrKSGmU0kC7n7grtPu/v05ORknzYNAJDSJfRnJU3Fnpebr8WtSDru7r919x8p6nPf158QAQBppEnoJyXtM7PrzGy7pCOSjifKfFVR61xmtktRF8wzfYwTANBDz4Tu7pck3S3pYUk/kPSgu58ys7qZ3d4s9rCkX5rZaUmPSPprd//loIIGAFwpVR+6uz/k7te7+++7+981X6u5+/HmY3f3D7n7fnd/o7s/MMigB4qJugDkFGeKJnHWKICcIqEncdYogJwqZh3AyKlWoxsA5AwtdAAIBAkdAAJBQgeAQJDQASAQJHQACAQJHQACQUIHgECQ0HthKgAAOUFC74WpAADkBAm9F6YCAJATnPrfC1MBAMgJWugYG41GQ1NTU2p0OB7SWl6pVLRz506VSiU1Gg01Gg1dddVVMjOZmSqVSup1AkPl7pncbrzxRgcGaWFhwcvlsi8sLLi7e7lcdkleLpfblm8tLxQKLuly2dbrrVuhULjiPeVy2efm5rxQKPjc3JwvLCx4qVTyiYmJy9sH+kHSsnfIqyR05FoyacclE3i3svHlc3Nz65LxwsKCF4vFywl9bm6u7fZb/wgKhcK6fwKt5d22DaRFQkcwNtLqHnYS7dZC3+g/F6ATEjqCkdfEuNHuH6ATEjpyJd71kUzWeUngvaTt/sl7PdF/3RK6RcuHb3p62peXlzPZNkbb1NSUVlZWVCgUtLa2pnK5rLNnz2Yd1lC19sE41h3dmdnj7j7dbhnDFpGpRqOhHTt2aNu2bZeHA9ZqNZXLZc3OzqpcLqs2hid1tfZBvO4MkUQvtNCRqVZLVJIKhYIuXbqUcUSji1Y7JFroGBGVSkXFYnHdiTm1Wk1XX321zEyzs7MZRjf62rXagTha6BiaYrGotbU1WuID0Gg0VK/XVavVVGWqiqDRQsfQtevvnZ2dVaFQoCU+APV6XSsrK6ozK+hYI6FjINolmMXFRV26dEmLi4sZRhamZHdMo9FYNx8NxgNdLhgIugCyFT/YzEHUsNDlgqGrVqs6e/YsyTwjtVpNpVJJExMT2r179xUHoxEmWuhA4DgYHRZa6MAYSx6M5gSlcJHQkUr84g8kg3xJHoyOH7AmuQem0yQv8ZukQ5KeknRG0j1dyr1D0RzQ073WyeRc+ZGc61vMEphr8Ym/JiYmXJKbGROB5YS6TM7Vs4VuZgVJ90m6VdJ+SbNmtr9NuVdK+qCkx/rwfwYjpF6vX+6DHef5VUIRP2BtZpKiht1HPvIRWus5l6bL5SZJZ9z9GXd/SdIDkg63KfcJScckXexjfBgBrTHO8/PzWlxcZPRKQI4dO6aJiQmVSiWZGScn5VyahL5bUnwQ60rztcvM7AZJU+7+tW4rMrOjZrZsZsvnzp3bcLDIBkMQw1WtVrW6uqrz58/r2LFj/PrKuS0fFDWzbZI+JenDvcq6+4K7T7v79OTk5FY3PRoqFalYjO5zrt3kWRgf7f5xc9A0X3qOQzezmyV93N3/tPn8Y5Lk7n/ffH6tpB9KeqH5lt+TdF7S7e7ecaB5MOPQi0VpbU0qFKScj/FlvDKSmLJ39Gx1HPpJSfvM7Doz2y7piKTjrYXu/ry773L3ve6+V9IJ9UjmQZmdjZJ5TiecirfAmDwLSUzZmzOdhr/4+uGIt0l6WlFL/N7ma3VFiTtZ9pti2GIuxIcjMgwRvXCd09EgrimKduLX7pyfn+egJ7pqfV8mJiZ0zTXXMPFaRjj1H5fFu1jiwxH5w0Qvre9La3jjRz/6UQ6Yjhha6GOiUqloaWlJ27dv169//WsOcmHTWlMjv/DCC7pw4QK/8IaMFjq0tLSktbU1Xbx4kYNc2JLW8MZPfvKTKhQKWltb42SkEUFCHxOtESx33HEHJwmhL6rVqubn5y83EBiznj26XAD0ReugaalU0o4dOzhoOiB0uQAYuNZBU3dnTpiMkNADwoWBkaV43zrHabJBl0sgGo2G7rrrLq2trUniwsBAqLp1uRSHHQwGozVnuZnp2muvpXUEjCG6XALR6r+8//77tbq6ysEoYAyR0APBnOXIA4Y2DhZ96ACGhul4t45hiwBGQqtrcGZmhpb6ANBCBzB0tNQ3jxY6gJHChTMGg4Q+4jiIhBBxEH8w6HIZcfw0BRBHl0sOtVrmMzMz/DTF2OAX6dbQQh9RtMwxjrgsYm+00HOEljnGWa1Wu3zRDC5xt3G00EcMLXOMu+Ql7vhbWI8WelYaDWlqKrpPieFcGHdMw7t5tNAHaWpKWlmRymWJFgawaa1WO1dBooWenVpNmpiQfvWrDbXSAaxXr9e5ClIKJPRBqlala66RVlclvojAptEVmQ4JfdBmZqRCIbpvYqwtsDHJM0v5G2qPPvRBa9OPzkgWYGvG+W+IPvQs1WpRMo/9VOTnI7A1/A21RwsdQG6N4+gXWugZqlQqKhaLqlQqWYcCBIfRL+uR0Aeo0WjoC1/4gtbW1rS0tJR1OEBw4l0vHCily2WgWgduJGlubk6Li4sZRwSEa1wOlG65y8XMDpnZU2Z2xszuabP8Q2Z22syeMLNvmNlrtxp0CFqth4WFBZI5MGAcKE3RQjezgqSnJb1N0oqkk5Jm3f10rMxbJD3m7i+a2V2SZtz9z7utdxxa6ADQb1ttod8k6Yy7P+PuL0l6QNLheAF3f8TdX2w+PSGpvJWAAQAblyah75YU75Baab7WyZ2Svr6VoAAAG1fs58rMbE7StKQ3d1h+VNJRSdqzZ08/Nw0AYy9NC/1ZSVOx5+Xma+uY2Vsl3Svpdnf/TbsVufuCu0+7+/Tk5ORm4h05jDMHMCrSHBQtKjooeouiRH5S0rvd/VSszJskfUXSIXf/nzQbDuWgaLFY1NramgqFgi5dupR1OAACt6WDou5+SdLdkh6W9ANJD7r7KTOrm9ntzWL/IOkaSV82s++a2fE+xT7yZmdnVSgUNDs7m/5Nm7iSEYCtC/3kI04sygJXMgIy0Tr5qFAoaH5+PpfzvzCXy6hpMwMjgMGr1WoqFApaW1sLcv4XEnoWqtWoZZ7D1gGQZ9VqVfPz88HO/0KXC4Cxlcf5X+hyAYA2Qpv/hYTeQ2g/yQC8LHmt0ryjy6WHPP4kAxAuuly2ILSfZAC6y/OvclroABAz6r/KaaFvQJ7/OwPYutav8pmZmdzlAlroCaP+3xnAcIxqLqCFvgH0mQOQ8tlSp4WuaArcpaUlzc7Ocu1PAOuUSiVduHBBExMTWl1dzTocWui9LC0taW1tTUtLS1mHAmDEmNm6+1FGQtcmp8AFMBaOHTumcrmsY8eOZR1KT3S5AECO0OWSwNBEAFsxqjlkLFvoozocCUA+ZJlDaKEnMDQRwFaMag4ZyxY6AOQVLXQAGAMkdAAIRNAJ/eDBgzIzHTx4MOtQAASuUqmoWCyqUqlkFkPQCf2xxx5bd58LjYY0NRXdA8iNUTjjPOiEfuDAgXX3uVCvSysr0T2A3BiFM84Z5TJqGo0omddqUiDXOQTQP4xyyZNqVTp7lmQO5FwWZ5PSQgeAARjU2aS00AFgyLI4m5QWOgDkCC10ABgDJPRRxXh0ABtEQh9VjEcHgjTI0S+pErqZHTKzp8zsjJnd02b575jZl5rLHzOzvf0OtKXRaGjnzp0qlUojN7l8X9VqUrkc3QMIRr1e18rKiuoDaKz1TOhmVpB0n6RbJe2XNGtm+xPF7pS06u5/IOmfJA3s4nv1el2rq6u6cOHCQHbIyGA8OhCkQY5+SdNCv0nSGXd/xt1fkvSApMOJMocl/Xvz8Vck3WIDukR2rVZTqVTSxMTEyE0uDwC9VKtVnT17VtUBNNbSJPTdkuKj4lear7Ut4+6XJD0v6Xf7EWBStVrV+fPntbq6OpAdMnLSHhxtNKRSSdqxI7pPlq9UpGJROnjw5fW13rNzZ/S4VSY5W1yjEZUplaJlaeNJlmu3/kYjinnbtpdfb7233baS6+22fzZSNrndVn1b++mqqySz6JaMv7XOeP3i+6y1js3E0q3uvera2v7Bg+v3ezLmbduiz6DX/k5+LpXK+u9Pt8+t3T5uVyb+nYyX6bT/upXptF/bxdyuzq11J/dfp88i+f3uFM8gBzy4e9ebpHdK+tfY84qkf06UeVJSOfb8h5J2tVnXUUnLkpb37NnjSKFcdpei+zTlWrdk+ULhyuXx95TLL5cpFDqvu1UmbTzxcu3Wn1x3/LV220qut9v+2UjZdtttt586xZ/cf8l9u9lYutU9TV3bxd0u5jT7O7l/Ou2nbt+RXmU6fdc61a9bmW77tdt72n0Pun3uLcnvd6d40v5NdyBp2Tvl604LLheQbpb0cOz5xyR9LFHmYUk3Nx8XJf1CzZOWOt1uvPHGTVVm7CwsRB/8wkLvchMT7ldfHd0ny8/NRV+0AwdeXl/rPaVS9LhVZm7uynWXSlHZubn08STLtVv/wkIUs9nLr7fe225byfV22z8bKZvcbqu+rf1ULL78h52Mv7XOeP3i+6y1js3E0q3uvera2v6BA+v3ezJms+gz6LW/k5/L3Nz670+3z63dPm5XJv6djJfptP+6lem0X9vF3K7OrXUn91+nzyL5/e4UT9q/6Q66JfSeZ4qaWVHS05JukfSspJOS3u3up2Jl3i/pje7+PjM7Iunt7v6ubuvlTFEA2LhuZ4oWe73Z3S+Z2d2KWuEFSZ9191NmVlf0n+K4pH+TtGhmZySdl3Skf+EDANLomdAlyd0fkvRQ4rVa7PFFSX/W39AAABvBmaIAEAgSOgAEgoQOAIEgoQNAIEjoABCIzK5YZGbnJP1kg2/bpeikpXFDvccL9R4/G6n7a919st2CzBL6ZpjZcqcB9SGj3uOFeo+fftWdLhcACAQJHQACkbeEvpB1ABmh3uOFeo+fvtQ9V33oAIDO8tZCBwB0MHIJfZQuSD1sKer+ITM7bWZPmNk3zOy1WcTZb73qHSv3DjNzMwtiJESaepvZu5qf+Skz++KwYxyEFN/zPWb2iJl9p/ldvy2LOPvNzD5rZs+Z2ZMdlpuZfbq5X54wsxs2vJFOE6VncVM0Pe8PJb1O0nZJ35O0P1HmryR9pvn4iKQvZR33EOv+FklXNx/fFULd09S7We6Vkh6VdELSdNZxD+nz3ifpO5JKzeevzjruIdV7QdJdzcf7Jf0467j7VPc/knSDpCc7LL9N0tclmaSDkh7b6DZGrYU+UhekHrKedXf3R9z9xebTE5LKQ45xENJ85pL0CUnHJF0cZnADlKbeVUn3ufuqJLn7c0OOcRDS1Nslvar5+FpJPxtifAPj7o8qul5EJ4clfd4jJyRNmNlrNrKNUUvoI3VB6iFLU/e4OxX9N8+7nvVu/vSccvevDTOwAUvzeV8v6Xoz+5aZnTCzQ0OLbnDS1PvjkubMbEXRdRg+MJzQMrfRHHCFVBe4wGgxszlJ05LenHUsg2Zm2yR9StJ7Mw4lC0VF3S4zin6NPWpmb3T3C5lGNXizkj7n7v9oZjcruhraG9z9/7IObNSNWgv9WUlTsefl5mttyzSvd3qtpF8OJbrBSlN3mdlbJd0r6XZ3/82QYhukXvV+paQ3SPqmmf1YUd/i8QAOjKb5vFckHXf337r7jxRd23ffkOIblDT1vlPSg5Lk7t+W9ApFc52ELlUO6GbUEvpJSfvM7Doz267ooOfxRJnjkv6i+fidkv7Lm0cUcq5n3c3sTZLuV5TMQ+hPlXrU292fd/dd7r7X3fcqOnZwu7vn/Qrjab7rX1XUOpeZ7VLUBfPMMIMcgDT1/qmii9LLzF6vKKGfG2qU2Tgu6T3N0S4HJT3v7j/f0BqyPvLb4Ujv04qOhN/bfK2u6I9Yij7cL0s6I+m/Jb0u65iHWPf/lPS/kr7bvB3POuZh1DtR9psKYJRLys/bFHU3nZb0fUlHso55SPXeL+lbikbAfFfSn2Qdc5/qvSTp55J+q+jX152S3ifpfbHP+77mfvn+Zr7nnCkKAIEYtS4XAMAmkdABIBAkdAAIBAkdAAJBQgeAQJDQASAQJHQACAQJHQAC8f8+KI6ty2sn+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the activation of the 0-th hidden node\n",
    "x = tf.random.uniform((100, 1, 1), minval=0.0, maxval=1.0)\n",
    "y = f(x)\n",
    "y_obs = sinModel.hl_act(0, x)\n",
    "\n",
    "plt.scatter(x, y, c=\"black\", s=3)\n",
    "plt.scatter(x, y_obs, c=\"red\", s=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkR9VW56xEpj"
   },
   "source": [
    "## 4-layer version\n",
    "\n",
    "Commonly used activation functions like sigmoid and the rectified linear don't usually tend toward zero on both ends. However, inserting another hidden layer allows us to use sigmoidal activation functions.\n",
    "\n",
    "Broadly, the purpose of the nodes in the second hidden layer is the same as the hidden nodes in the 3-layer version: to activate when the input is close to some fixed value. The nodes in the first hidden layer should be zero, when read from left to right, until some node where the values switch to one.\n",
    "\n",
    "Speaking of the hidden layers in terms of signals, the second hidden layer is the \"derivative\" of the first, and the feed-forward calculation between them can be compared to convolving the first signal with the $\\delta$ signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWqwROWKYaSv"
   },
   "source": [
    "---\n",
    "\n",
    "# Helpful Mathematical Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kcWiTr6jzWc"
   },
   "source": [
    "## Linear Systems Background\n",
    "\n",
    "Some vocabulary:\n",
    "\n",
    "* **Def** A _signal_ (denoted with $x$ or $y$) just refers to a real-valued function (usually over time). Alternatively, it can be thought of as a list of (output) values.\n",
    "* **Def** _Shifted signal_: $x \\Rsh s$ is the signal such that $(x \\Rsh s)(t) = x(t - s)$. Usually, $x(t - s)$ denotes the shifted signal itself, but using the denotation $\\Rsh$ clarifies that shifting is an operation on a signal. \n",
    "* **Def** A _system_ or _transform_ (denoted $T$) is a \"function on functions\", a transformation from one signal to another.\n",
    "* **Def** A _linear system_ is a system that satisfies homogeneity and additivity from linear algebra.\n",
    "* **Def** A _shift-invariant system_ $T$ satisfies the property $T[x \\Rsh s] = T[x] \\Rsh s$ for any signal and shift amount.\n",
    "* **Def** The _unit impulse_ signal (denoted $\\delta(t)$) is a spike at time zero and is defined such that:\n",
    "$$ \\int_{-\\infty}^{t} \\delta(\\tau)\\ d\\tau = \\begin{cases} 0 \\qquad t < 0 \\\\ 1 \\qquad t > 0 \\end{cases}$$\n",
    "\n",
    "Any signal can be represented as a linear combination of shifted and scaled impulse signals:\n",
    "$$ x(t) = \\int_{-\\infty}^{\\infty} x(\\tau)\\ \\delta(t - \\tau)\\ d\\tau $$\n",
    "\n",
    "Suppose $T$ is a linear shift-invariant transform. Then, by properties of linearity and shift-invariance:\n",
    "$$ T[x(t)] = \\int_{-\\infty}^{\\infty} x(\\tau)\\ (T[\\delta])(t - \\tau) \\ d\\tau $$\n",
    "This means that $T$ is completely characterized by how it maps the unit impulse signal. $T[\\delta]$ is called the _impulse response signal_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lV_WsO4Bq5g6"
   },
   "source": [
    "**Def** A _convolution_ is a combination of two signals. We say $x * y$ is the result of convolving $x$ with $y$.\n",
    "  $$ (x * y)(t) = \\int_{-\\infty}^{\\infty} x(\\tau)\\ y(t - \\tau)\\ d\\tau $$\n",
    "  $$ x * y = \\int_{-\\infty}^{\\infty} x(\\tau)\\ (y \\Rsh \\tau)\\ d\\tau $$\n",
    "  Think of convolution as constructing a new signal that is a linear combination of a set of base signals. But each base signal is just a shifted version of a single signal $y$. The factors that scale the base signals are the outputs of $x$.\n",
    "\n",
    "Special Convolutions:\n",
    " * $x * \\delta = x$\n",
    " * $x * 1 = \\int_{-\\infty}^{\\infty} x(\\tau)\\ d\\tau$\n",
    " * $x * \\text{step} = \\int_{-\\infty}^{t}x(\\tau)\\ d\\tau \\qquad$ (\"step\" is the integral of $\\delta$)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGLvr2-LjP1E"
   },
   "source": [
    "Differentiation on real functions is a shift-invariant linear operation, so it can be expressed as a convolution ($d$ is the \"derivative\" of $\\delta$):\n",
    "$$ \\frac{dx}{dt} = x * d = \\int_{-\\infty}^{\\infty} x(\\tau)\\ (d \\Rsh \\tau)\\ d\\tau $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9u25xiz6B_X"
   },
   "source": [
    "A Taylor series is similar to a convolution, but uses a discrete sum instead of the continuous integral.\n",
    "\n",
    "$$ f(x) = \\sum_{n=0}^{\\infty} \\frac{f^{(n)}(a)}{n!} (x - a)^n \\qquad \\forall x, a \\in \\mathbb{R} $$\n",
    "\n",
    "$$ f(x) = \\sum_{n=0}^\\infty \\frac{f^{(n)}(0)}{n!} x^n $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faQpaJauIQ6W"
   },
   "source": [
    "## Neural Net vs. Fuzzy Inference System\n",
    "\n",
    "The feedforward calculation of a neural network is a (linear) affine transformation composed with a nonlinear function $\\sigma$.\n",
    "\n",
    "$$ x^{(l+1)} = \\sigma(W^{(l)} x^{(l)} + b^{(l)}) \\qquad \\text{whole layer}$$\n",
    "\n",
    "$$ x^{(l+1)}_i = \\sigma\\left( \\sum_j W_{i,j}^{(l)} x_j^{(l)} + b_i^{(l)} \\right) \\qquad \\text{single node} $$\n",
    "\n",
    "_Index confusion_:\n",
    "* _Superscripts in parentheses_ always refer to the layer.\n",
    "* _Subscripts_ index the elements within a particular layer. Vectors only have one subscript. Matrices have two comma-separated subscripts for the _row_ and _col_ respectively. Letting the _col_ vary looks like moving left-right across the matrix.\n",
    "* Matrix vector multiplication example: $\\sum_j W_{i,j}x_j = (Wx)_i$\n",
    "\n",
    "### Piecewise-linear neural network\n",
    "\n",
    "If the activation function $\\sigma$ is piecewise-linear, such as a rectified linear or absolute value, then the entire feed-forward network will be piecewise-linear because composing two piecewise-linear functions yields another piecewise-linear function.\n",
    "\n",
    "**Theorem** The composition of two piecewise-affine functions is itself piecewise-affine.\n",
    "\n",
    "**Proof** Let $f$ and $g$ be piecewise-affine. Since $f$ is piecewise, the domain of $f$ can be divided into regions $\\{r_1, r_2, ...\\}$ such that $f$ is purely affine on any one region $r_i$. The same can be said for $g$ on regions $\\{s_1, s_2, ...\\}$. Now the composition of two purely affine functions is itself affine. This means that $(g \\circ f)$ is affine on any region $r_i \\cap \\{x | f(x) \\in s_j\\}$ since this region is a subset of $r_i$, and its mapping via $f$ is a subset of $s_j$. So $(g \\circ f)$ is piecewise-affine.\n",
    "\n",
    "### Fuzzy Inference System\n",
    "\n",
    "The function defined by a fuzzy inference system $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ is piecewise-polynomial of degree $n$. This is because for each region in the domain, $f$ is defined as a linear combination of $2^n$ membership functions. As an example, for a one-input one-output system, on the domain $[0,1]$, these membership functions are $(1 - x)$ and $x$.\n",
    "\n",
    "$$ f(x) = c_0(1 - x) + c_1x $$\n",
    "\n",
    "If the input becomes 2-dimensional, then $f$ on the unit square becomes:\n",
    "\n",
    "$$ f(x,y) = c_{00}(1-x)(1-y) + c_{01}(1-x)y + c_{10}x(1-y) + c_{11}xy $$\n",
    "\n",
    "Each additional variable requires an additional multiplication in the definition of the membership functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1n-Av1fvLDQp"
   },
   "source": [
    "## Universal Approximation Theorem\n",
    "\n",
    "The universal approximation theorem says that neural networks with either arbitrary width or depth can approximate any continuous function to arbitrary accuracy.\n",
    "\n",
    "* **Arbitrary Width** Given a non-polynomial activation function $\\sigma: \\mathbb{R} \\rightarrow \\mathbb{R}$ and input,output dimensions $d,D \\in \\mathbb{Z}^+$\n",
    " * for every continuous function $f: \\mathbb{R}^d \\rightarrow \\mathbb{R}^D$,\n",
    " * for every compact subset $K$ of $\\mathbb{R}^d$,\n",
    " * for every $\\epsilon > 0$,\n",
    " * there exists linear affine maps $W_1, W_2$ such that\n",
    " * $\\sup| f(x) - (W_2 \\circ \\sigma \\circ W_1)(x) | < \\epsilon$\n",
    "* **Arbitrary Depth**\n",
    " * for every function $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$,\n",
    " * for every $\\epsilon > 0$,\n",
    " * there exists a fully-connected ReLU network $F$ with width $d_m = \\max\\{n+1,m\\}$ such that,\n",
    " * $\\int_{\\mathbb{R}^n} | f(x) - F(x) |^p dx < \\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yt_hgDzz30c"
   },
   "source": [
    "## Fourier Series\n",
    "\n",
    "Fourier's Theorem states that any periodic function $f$ with period $L$ can be written as a sum of sines and cosines:\n",
    "\n",
    "$$ f(x) = a_0 + \\sum_{n=1}^{\\infty} \\left[ a_n\\cos\\left(\\frac{2\\pi nx}{L}\\right) + b_n\\sin\\left(\\frac{2\\pi nx}{L}\\right) \\right] \\qquad \\text{(Fourier's Theorem)} $$\n",
    "\n",
    "where the coefficients can be calculated as follows:\n",
    "\n",
    "$$ a_n = \\frac{2}{L}\\int_0^{L} f(x)\\cos\\left( \\frac{2\\pi nx}{L} \\right)\\ dx $$\n",
    "$$ b_n = \\frac{2}{L}\\int_0^{L} f(x)\\sin\\left( \\frac{2\\pi nx}{L} \\right)\\ dx $$\n",
    "\n",
    "There is an equivalent exponential form that also generalizes to complex functions:\n",
    "\n",
    "$$ f(x) = \\sum_{n=-\\infty}^{\\infty} C_n e^{i\\, 2\\pi nx/L} \\qquad \\text{(Fourier's Theorem)} $$\n",
    "\n",
    "$$ C_n = \\frac{1}{L}\\int_0^L f(x) e^{i\\, 2\\pi nx/L}\\ dx $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOD0kL4hQ1Lv"
   },
   "source": [
    "## Fourier Approximations\n",
    "\n",
    "Fourier approximations work because the set of functions $\\{\\frac{1}{\\pi}\\sin nx | n \\ge 1\\} \\cup \\{\\frac{1}{\\pi} \\cos nx | n \\ge 1\\} \\cup \\{\\frac{1}{2\\pi}\\}$ forms an orthonormal basis of the set of real-valued functions with period $2\\pi$. This is because:\n",
    "\n",
    "* All functions in this set have unit length (e.g. $\\int_0^{2\\pi} \\sin^2 (nx)\\ dx = 1$)\n",
    "* All functions in this set are pairwise orthogonal (e.g. $\\int_0^{2\\pi} \\sin(nx)\\cos(mx)\\ dx = 0$)\n",
    "* There are \"enough\" of them to span the entire vector space\n",
    "\n",
    "Finding the Fourier approximation of a function $f$ just requires calculating the coorinates of $f$ in this new basis. Recall the projection formula:\n",
    "\n",
    "$$ \\text{proj}_{\\vec{w}} \\vec{v} = \\frac{\\vec{v} \\cdot \\vec{w}}{||\\vec{w}||^2} \\vec{w} $$\n",
    "\n",
    "So we just need to project our function $f$ onto each basis vector. For example,\n",
    "\n",
    "$$ \\text{proj}_{\\sin(x)/\\pi} f = \\frac{1}{\\pi^2} \\left( \\int_0^{2\\pi} f(x) \\sin(x)\\ dx \\right) \\sin(x) $$\n",
    "\n",
    "Similar approximations can be done with any set of orthogonal functions such as [orthogonal polynomials](https://en.wikipedia.org/wiki/Orthogonal_polynomials)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lbEMxF8W7sp"
   },
   "source": [
    "The discrete Fourier Transform transforms a sequence of complex numbers $ x_0, x_2, \\dots, x_{N-1} $ into another sequence:\n",
    "\n",
    "$$ X = F\\pmb{x} $$\n",
    "\n",
    "$$ \\begin{bmatrix} X_0 \\\\ X_1 \\\\ \\vdots \\end{bmatrix} = \\begin{bmatrix} \\omega^{0 \\cdot 0} & \\omega^{0 \\cdot 1} & \\\\ \\omega^{1 \\cdot 0} & \\omega^{1 \\cdot 1} & \\cdots \\\\ & \\vdots & \\end{bmatrix} \\begin{bmatrix} x_0 \\\\ x_1 \\\\ \\vdots \\end{bmatrix} $$\n",
    "\n",
    "$$ \\omega = e^{-\\frac{2 \\pi i}{N}} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TT2evCQasjc"
   },
   "source": [
    "## Spline Theory\n",
    "\n",
    "Notes from \"A Spline Theory of Deep Networks\" by Balestriero and Baraniuk.\n",
    "\n",
    "* **Def** A function $f: \\mathbb{R^n} \\rightarrow \\mathbb{R}$ is _convex_ if the line segment connecting any two points on the graph lies entirely above the graph (think positive concavity or positive second derivative).\n",
    "* **Def** An _affine spline_ is a continuous piecewise-affine function ($\\mathbb{R^n} \\rightarrow \\mathbb{R}$).\n",
    "* **Def** A _max-affine spline_ is defined as the maximum of a set of affine functions over the entire domain. Max-affine splines are necessarily globally convex and continuous no matter the choices of affine functions.\n",
    "* **Def** An _adaptive-partitioning spline_ (such as a max-affine spline) is a spline were the domain partitioning is not a direct parameter, but instead determined by other parameters, and where the domain partitioning automatically changes as the direct parameters change.\n",
    "* **Def** An _affine spline operator_ is obtained by simply concatenating affine splines to produce a function with multivariate output.\n",
    "* **Def** A _max-affine spline operator_ (MASO) is an affine spline operator produced by concatenating max-affine splines.\n",
    "\n",
    "Main result: most deep networks can be written as a composition of MASOs, one for each layer, even though a MASO can only approximate a convex function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VvvNnEY4Er_b"
   },
   "source": [
    "## Linear Regression with Vectors\n",
    "\n",
    "Suppose we have $n$ datapoints $(x_i, y_i)$ where $x_i, y_i \\in \\mathbb{R}$. A linear regression problem attempts to find a function $f(x) = mx + b$ such that some sort of error function, like square differences, are minimized. This problem can reframed as finding values of $m,b$ such that the approximation below is \"closest\"\n",
    "\n",
    "$$ \\pmb{y} \\approx X \\pmb{ w } $$\n",
    "$$ \\begin{bmatrix} y_0 \\\\ y_1 \\\\ \\vdots \\end{bmatrix} \\approx \\begin{bmatrix} x_0 & 1 \\\\ x_1 & 1 \\\\ \\vdots & \\vdots \\end{bmatrix} \\begin{bmatrix} m \\\\ b \\end{bmatrix} $$\n",
    "\n",
    "Here is another interpretation of the above equation: Given each $x_i$, the vector $\\pmb{y}$ is a representation of a function (think of \"coordinates\"). It represents a function by simply listing outputs associated with the given inputs. This vector sits in some vector space $V$. The columns of the $X$ matrix are also vectors in $V$ (representations of $x \\mapsto x$ and $x \\mapsto 1$).\n",
    "\n",
    "But $\\pmb{w}$ is a different representation of a function in a different, lower-dimensional vector space $W$. The matrix $X$ maps vectors from $W$ into $V$. The problem now becomes: \"find the vector $\\pmb{w}$ such that the distance from $\\pmb{y}$ to $X\\pmb{w}$ is minimum\":\n",
    "\n",
    "$$ \\pmb{w} = \\min_{w} || Xw - \\pmb{y} ||^2 $$\n",
    "\n",
    "There are two ways of finding $\\pmb{w}$. The more traditional way is to use calculus. The partial derivatives are taken with respect to $m$ and $b$. Note that this is just another way to say that the sum of the square differences must be minimum.\n",
    "\n",
    "$$ \\nabla || X\\pmb{w} - \\pmb{y} ||^2 = \\pmb{0} $$\n",
    "\n",
    "Another way is to project the vector $\\pmb{y}$ onto the space $X(W)$. The vectors $\\pmb{w_i}$ can be any orthogonal basis of $W$.\n",
    "\n",
    "$$ X(\\pmb{w}) = \\text{proj}_{X(W)}(\\pmb{y}) = \\sum_i \\frac{\\pmb{y} \\cdot X(\\pmb{w_i})}{|| X(\\pmb{w_i}) ||^2} X(\\pmb{w_i}) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "PhP3ND14ZWyK",
    "outputId": "10927112-416c-43f3-e903-7610c4891a03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximation: 0.40 + 0.60x + -1.41x^2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example: quadratic regression using the projection method\n",
    "\n",
    "# Generate data   yvec = 0.5sin(pi xvec + pi/4)\n",
    "n = 11\n",
    "xvec = np.linspace(0.0, 1.0, num=n)\n",
    "yvec = 0.5 * np.sin(np.pi * xvec + np.pi * 0.25)\n",
    "xsquarevec = xvec ** 2.0\n",
    "onesvec = np.ones((n,))\n",
    "\n",
    "# Construct the X matrix\n",
    "X = np.column_stack((onesvec, xvec, xsquarevec))\n",
    "\n",
    "# Calculate Xw by projecting onto the orthogonal basis \"Xorth\"\n",
    "Xorth, _ = np.linalg.qr(X)\n",
    "Xw = np.zeros((n, 1))\n",
    "for c in range(3):\n",
    "  col = Xorth[:,c:c+1]\n",
    "  Xw = Xw + (np.matmul(yvec, col) / np.sum(col ** 2.0)) * col\n",
    "\n",
    "# To get the original w vector, take any three coordinates from\n",
    "# Xw and the corresponding rows from T. Then w = inv(X) Xw\n",
    "Xsquare = np.resize(X, (3, 3))\n",
    "w = np.matmul(np.linalg.inv(Xsquare), np.resize(Xw, (3,1)))\n",
    "print(\"Approximation: {:.2f} + {:.2f}x + {:.2f}x^2\".format(w[0,0], w[1,0], w[2,0]))\n",
    "\n",
    "plt.plot(xvec, yvec, color=\"red\")\n",
    "plt.plot(xvec, [w[0,0] + w[1,0]*x + w[2,0]*x*x for x in list(xvec)])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSa2iWcBqFRz"
   },
   "source": [
    "## Dimensionality Reduction\n",
    "\n",
    "* **Def** _Dimensionality reduction_ refers to some method of squeezing high dimensional data into a lower dimensional space in some meaningful way. These transformations can be linear or non-linear.\n",
    "* **Def** _Feature selection_ is probably the simplest linear dimensionality reduction strategy. You simply eliminate one or more variables that are deemed unimportant.\n",
    "* **Def** _Feature projection_ a generic linear dimensionality reduction strategy. Instead of naively eliminating one or more variables, you linearly-project the data into a smaller dimensional space. Think of rewriting the data in a different basis, then performing a feature selection.\n",
    "\n",
    "* **Def** The _covariance_ of two random variables $X,Y$ is a measure of their correlation. A covariance near zero means they are independent. While univariable variance is $E(X - E(X))^2$, covariance is $E(X - E(X))(Y - E(Y))$.\n",
    "* **Def** The _covariance matrix_ of $d$-dimensional data is a $d \\times d$ matrix containing the covariances of each pair of dimensions.\n",
    "\n",
    "The eigenvectors of the covariance matrix represent sort of the \"principal components\" of the distribution. If you were to rewrite the data using the eigenvector coordinates, the eigenvectors corresponding to the largest eigenvalues represent the directions in which the data is the most \"spread out\" or the most varied.\n",
    "\n",
    "* **Def** _Principal Component Analysis_ is the primary version of feature projection where we keep the features in which the data is the most varied and eliminate features where the data does not vary as much. We can do this by rewriting the data in terms of a basis of eigenvectors of the covariance matrix and discard the \"shortest eigenvectors\" (smallest eigenvalues).\n",
    "\n",
    "* **Dynamic Mode Decomposition** Another feature projection technique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "id": "yLpzCW_Y9ZHy",
    "outputId": "8e14d8d5-e32a-4cd1-9f2c-77cec33c9fce"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"422pt\" height=\"260pt\"\n",
       " viewBox=\"0.00 0.00 422.00 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-256 418,-256 418,4 -4,4\"/>\n",
       "<!-- i -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>i</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"207\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"207\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x</text>\n",
       "</g>\n",
       "<!-- o -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>o</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"207\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"207\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">y</text>\n",
       "</g>\n",
       "<!-- a -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>a</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0</text>\n",
       "</g>\n",
       "<!-- o&#45;&#45;a -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>o&#45;&#45;a</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M182.7416,-225.7783C153.869,-215.7927 104.3615,-198.0365 63,-180 58.2601,-177.9331 53.2525,-175.5571 48.5278,-173.2234\"/>\n",
       "</g>\n",
       "<!-- b -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>b</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"99\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0</text>\n",
       "</g>\n",
       "<!-- o&#45;&#45;b -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>o&#45;&#45;b</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M187.6918,-221.1278C168.0337,-208.0225 137.7386,-187.8257 118.1411,-174.7607\"/>\n",
       "</g>\n",
       "<!-- d -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>d</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"243\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0</text>\n",
       "</g>\n",
       "<!-- o&#45;&#45;d -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>o&#45;&#45;d</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M215.7146,-216.5708C221.3747,-205.2506 228.7216,-190.5568 234.3657,-179.2687\"/>\n",
       "</g>\n",
       "<!-- e -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>e</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"315\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"315\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0</text>\n",
       "</g>\n",
       "<!-- o&#45;&#45;e -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>o&#45;&#45;e</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M226.3082,-221.1278C245.9663,-208.0225 276.2614,-187.8257 295.8589,-174.7607\"/>\n",
       "</g>\n",
       "<!-- f -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>f</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"387\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"387\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0</text>\n",
       "</g>\n",
       "<!-- o&#45;&#45;f -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>o&#45;&#45;f</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M231.2584,-225.7783C260.131,-215.7927 309.6385,-198.0365 351,-180 355.7399,-177.9331 360.7475,-175.5571 365.4722,-173.2234\"/>\n",
       "</g>\n",
       "<!-- c -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>c</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"171\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1</text>\n",
       "</g>\n",
       "<!-- o&#45;&#45;c -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>o&#45;&#45;c</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M198.2854,-216.5708C192.6253,-205.2506 185.2784,-190.5568 179.6343,-179.2687\"/>\n",
       "</g>\n",
       "<!-- u -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>u</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"63\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0</text>\n",
       "</g>\n",
       "<!-- u&#45;&#45;i -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>u&#45;&#45;i</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M84.8705,-79.0647C112.0934,-65.4533 158.297,-42.3515 185.3955,-28.8022\"/>\n",
       "</g>\n",
       "<!-- v -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>v</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"135\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"135\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0</text>\n",
       "</g>\n",
       "<!-- v&#45;&#45;i -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>v&#45;&#45;i</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M150.2693,-74.7307C162.488,-62.512 179.5398,-45.4602 191.7527,-33.2473\"/>\n",
       "</g>\n",
       "<!-- a&#45;&#45;u -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>a&#45;&#45;u</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M35.7146,-144.5708C41.3747,-133.2506 48.7216,-118.5568 54.3657,-107.2687\"/>\n",
       "</g>\n",
       "<!-- b&#45;&#45;u -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>b&#45;&#45;u</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M90.2854,-144.5708C84.6253,-133.2506 77.2784,-118.5568 71.6343,-107.2687\"/>\n",
       "</g>\n",
       "<!-- b&#45;&#45;v -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>b&#45;&#45;v</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M107.7146,-144.5708C113.3747,-133.2506 120.7216,-118.5568 126.3657,-107.2687\"/>\n",
       "</g>\n",
       "<!-- w -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>w</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"207\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"207\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1</text>\n",
       "</g>\n",
       "<!-- d&#45;&#45;w -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>d&#45;&#45;w</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M234.2854,-144.5708C228.6253,-133.2506 221.2784,-118.5568 215.6343,-107.2687\"/>\n",
       "</g>\n",
       "<!-- x -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>x</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"279\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"279\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1</text>\n",
       "</g>\n",
       "<!-- d&#45;&#45;x -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>d&#45;&#45;x</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M251.7146,-144.5708C257.3747,-133.2506 264.7216,-118.5568 270.3657,-107.2687\"/>\n",
       "</g>\n",
       "<!-- e&#45;&#45;x -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>e&#45;&#45;x</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M306.2854,-144.5708C300.6253,-133.2506 293.2784,-118.5568 287.6343,-107.2687\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>y</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"351\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"351\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1</text>\n",
       "</g>\n",
       "<!-- e&#45;&#45;y -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>e&#45;&#45;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M323.7146,-144.5708C329.3747,-133.2506 336.7216,-118.5568 342.3657,-107.2687\"/>\n",
       "</g>\n",
       "<!-- f&#45;&#45;y -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>f&#45;&#45;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M378.2854,-144.5708C372.6253,-133.2506 365.2784,-118.5568 359.6343,-107.2687\"/>\n",
       "</g>\n",
       "<!-- w&#45;&#45;i -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>w&#45;&#45;i</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M207,-71.8314C207,-61 207,-47.2876 207,-36.4133\"/>\n",
       "</g>\n",
       "<!-- x&#45;&#45;i -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>x&#45;&#45;i</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M263.7307,-74.7307C251.512,-62.512 234.4602,-45.4602 222.2473,-33.2473\"/>\n",
       "</g>\n",
       "<!-- y&#45;&#45;i -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>y&#45;&#45;i</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M329.1295,-79.0647C301.9066,-65.4533 255.703,-42.3515 228.6045,-28.8022\"/>\n",
       "</g>\n",
       "<!-- c&#45;&#45;v -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>c&#45;&#45;v</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M162.2854,-144.5708C156.6253,-133.2506 149.2784,-118.5568 143.6343,-107.2687\"/>\n",
       "</g>\n",
       "<!-- c&#45;&#45;w -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>c&#45;&#45;w</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M179.7146,-144.5708C185.3747,-133.2506 192.7216,-118.5568 198.3657,-107.2687\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Graph at 0x7fa45ebb47b8>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gv.Graph()\n",
    "g.node(\"i\", \"x\")\n",
    "g.node(\"o\", \"y\")\n",
    "for n in [\"u\", \"v\", \"a\", \"b\", \"d\", \"e\", \"f\"]: g.node(n, \"0\")\n",
    "for n in [\"w\", \"x\", \"y\", \"c\"]: g.node(n, \"1\")\n",
    "g.edges([\"oa\", \"ob\", \"oc\", \"od\", \"oe\", \"of\"])\n",
    "g.edges([\"au\", \"bu\", \"bv\", \"cv\", \"cw\", \"dw\", \"dx\", \"ex\", \"ey\", \"fy\"])\n",
    "g.edges([\"ui\", \"vi\", \"wi\", \"xi\", \"yi\"])\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFTFQh0pijW3"
   },
   "source": [
    "# Related Work\n",
    "\n",
    "https://math.stackexchange.com/questions/3147754/why-do-deep-neural-networks-work-well\n",
    "\n",
    "[Movement trajectory classification using supervised machine learning](http://kth.diva-portal.org/smash/get/diva2:1376904/FULLTEXT01.pdf)\n",
    "\n",
    "### Cheng, Model Compression for DNNs survey\n",
    "\n",
    "[Paper](https://arxiv.org/pdf/1710.09282.pdf)\n",
    "\n",
    "* Parameter pruning and quantization\n",
    "* Low-rank factorization\n",
    "* Transferred/compact convolutional filters\n",
    "* Knowledge distillation\n",
    "\n",
    "### Safran, Depth-Width Tradeoffs in Approximating Natural Functions with Neural Networks\n",
    "\n",
    "[Paper](https://arxiv.org/pdf/1610.09887.pdf)\n",
    "\n",
    "* Large enough networks of depth 2 can approximate any  continuous target function on $[0, 1]^d$ to arbitrary accuracy.\n",
    "* Deep network tend to outperform shallow networks of similar complexity.\n",
    "* **Def** The $L_p$-norm of a vector $v$ is $||v||_p = \\sqrt[p]{|v_0|^p + |v_1|^p + \\cdots}$\n",
    "* The the accuracy of expressing the indicator function of a Euclidean ball $\\pmb{x} \\mapsto \\begin{cases} 1 & ||\\pmb{x}||_2 \\le 1 \\\\ 0 & \\text{otherwise} \\end{cases}$ on a two-layer network requires width exponential in $d$ (the dimension of the input space). Same is not true of a three-layer network.\n",
    "* $L_1$ radial functions $\\pmb{x} \\mapsto f(||\\pmb{x}||_1)$ where $f$ is piecewise-linear can be represented _exactly_ by a 3-layer ReLU network, but not by a 2-layer network.\n",
    "\n",
    "### Neural Networks for Localized Approximation\n",
    "\n",
    "[Paper](https://www.ams.org/journals/mcom/1994-63-208/S0025-5718-1994-1240656-2/S0025-5718-1994-1240656-2.pdf)\n",
    "\n",
    "Question: Can neural networks satisfy a _local approximation_ property? i.e. that when the target function is modified only on a small subset of the Euclidean input space, only a few neurons need to be retrained.\n",
    "Result: 2-layer heavyside-activated networks cannot have this property if the input space is more than one-dimensional. In contrast, 3-layer networks or higher are capable of having this property for any-dimensional input spaces."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CPS491.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
