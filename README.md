# CPS 491 - Capstone II

Source: <https://bitbucket.org/capstones-cs-udayton/cps491.git>

University of Dayton

Department of Computer Science

CPS 491 - Capstone II, Semester Year

Instructor: Dr. Phu Phung


## Capstone II Project 


# Compressible Learning Agents for Autonomous Cyber-Physical Systems

# Team members

1.  Zachary Rowland, rowlandz1@udayton.edu


# Company Mentor

Matthew Clark, Principal Scientist

Galois

444 E 2nd Street

Dayton, OH 45402


# Project Management Information

Management board (private access): <https://trello.com/b/kVF2rdUV/cps-491-team-13>

Source code repository (private access): <https://github.com/cps491sp21-team13/cps491sp21-main-repo>

Project homepage (public): <https://cps491sp21-team13.github.io/>

## Revision History

| Date       |   Version     |  Description |
|------------|:-------------:|-------------:|
| DD/MM/YYYY |  0.0          | Init draft   |


# Overview

The goal of this project is to determine a method to compress a learning structure, such as a deep neural network or fuzzy network, into a minimum network required to satisfy the objective.

# Project Context and Scope

This project is a contribution to research into the development of machine learning models that learn intuitively.

# System Analysis

## High-level Requirements

List high-level requirements of the project that your team will develop into use cases in later steps

## Use cases

# System Design

## Use-Case Realization

## Database 

## User Interface


# Implementation

## Deployment

# Software Process Management

## Scrum process

### Sprint 0

Duration: 20/01/2021-27/01/2021

#### Completed Tasks: 

1. Studied fuzzy inference systems from material provided from Galois
2. Studied automatic differentiation.

#### Sprint Retrospection:

| Good     |   Could have been better    |  How to improve?  |
|----------|:---------------------------:|------------------:|
| learned a lot of preliminary information | documentation of progress | take more notes on what I read about/discover  |

### Sprint 1

Duration: 27/01/2021-03/02/2021

#### Completed Tasks:

1. Learned tensor manipulation and learning models in Tensorflow
2. Experimented with small neural networks in a Jupyter notebook

#### Sprint Retrospection:

| Good     |   Could have been better    |  How to improve?  |
|----------|:---------------------------:|------------------:|
| good pace aquiring new knowlege and documenting what I have learned | could have started experimenting with small networks sooner | reach out to ask questions sooner |

### Sprint 2

Duration: 03/02/2021-03/09/2021

#### Completed Tasks:

1. Learned about convolution from Linear Systems.
2. Detailed a technique for constructing neural networks that approximate arbitrary
   functions inspired by convolution.
3. Detailed a technique for approximating arbitrary polynomials with neural networks
   based on Taylor-series expansion.

#### Sprint Retrospection:

| Good     |   Could have been better    |  How to improve?  |
|----------|:---------------------------:|------------------:|
| documentation was thorough and clear | direction of work could have been more focused toward project goal | more formal communication about the precise goal of the project |

# User guide/Demo

# Acknowledgments 

I would like to thank Mr. Matthew Clark, Principal Scientist at Galois, for mentoring this project.
